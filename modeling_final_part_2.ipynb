{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/SXJ8JOZ/Downloads/ML/merged_data_clean_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CEO_FEMALE</th>\n",
       "      <th>EXECDIR_COUNT</th>\n",
       "      <th>AVG_SALARY</th>\n",
       "      <th>STD_SALARY</th>\n",
       "      <th>AVG_SALPCT</th>\n",
       "      <th>STD_SALPCT</th>\n",
       "      <th>AVG_TOTAL_COMP</th>\n",
       "      <th>NationalityMix</th>\n",
       "      <th>AVG_AGE</th>\n",
       "      <th>STD_AGE</th>\n",
       "      <th>Length_term</th>\n",
       "      <th>STDEVAge</th>\n",
       "      <th>TimeRetirement</th>\n",
       "      <th>TimeRole</th>\n",
       "      <th>TimeBrd</th>\n",
       "      <th>STDEVTimeBrd</th>\n",
       "      <th>TimeInCo</th>\n",
       "      <th>STDEVTimeInCo</th>\n",
       "      <th>TotNoLstdBrd</th>\n",
       "      <th>STDEVTotNoLstdBrd</th>\n",
       "      <th>TotNoUnLstdBrd</th>\n",
       "      <th>TotCurrNoLstdBrd</th>\n",
       "      <th>TotCurrNoUnLstdBrd</th>\n",
       "      <th>NoQuals</th>\n",
       "      <th>STDEVNoQuals</th>\n",
       "      <th>Succession</th>\n",
       "      <th>NetworkSize</th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>bm</th>\n",
       "      <th>evm</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>dpr</th>\n",
       "      <th>npm</th>\n",
       "      <th>opmbd</th>\n",
       "      <th>opmad</th>\n",
       "      <th>gpm</th>\n",
       "      <th>ptpm</th>\n",
       "      <th>cfm</th>\n",
       "      <th>roa</th>\n",
       "      <th>roe</th>\n",
       "      <th>roce</th>\n",
       "      <th>efftax</th>\n",
       "      <th>aftret_eq</th>\n",
       "      <th>aftret_invcapx</th>\n",
       "      <th>aftret_equity</th>\n",
       "      <th>pretret_noa</th>\n",
       "      <th>pretret_earnat</th>\n",
       "      <th>GProf</th>\n",
       "      <th>equity_invcap</th>\n",
       "      <th>debt_invcap</th>\n",
       "      <th>totdebt_invcap</th>\n",
       "      <th>capital_ratio</th>\n",
       "      <th>int_debt</th>\n",
       "      <th>int_totdebt</th>\n",
       "      <th>cash_lt</th>\n",
       "      <th>invt_act</th>\n",
       "      <th>rect_act</th>\n",
       "      <th>debt_at</th>\n",
       "      <th>debt_ebitda</th>\n",
       "      <th>short_debt</th>\n",
       "      <th>curr_debt</th>\n",
       "      <th>lt_debt</th>\n",
       "      <th>profit_lct</th>\n",
       "      <th>ocf_lct</th>\n",
       "      <th>cash_debt</th>\n",
       "      <th>fcf_ocf</th>\n",
       "      <th>lt_ppent</th>\n",
       "      <th>dltt_be</th>\n",
       "      <th>debt_assets</th>\n",
       "      <th>debt_capital</th>\n",
       "      <th>de_ratio</th>\n",
       "      <th>intcov</th>\n",
       "      <th>intcov_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>curr_ratio</th>\n",
       "      <th>cash_conversion</th>\n",
       "      <th>inv_turn</th>\n",
       "      <th>at_turn</th>\n",
       "      <th>rect_turn</th>\n",
       "      <th>pay_turn</th>\n",
       "      <th>sale_invcap</th>\n",
       "      <th>sale_equity</th>\n",
       "      <th>sale_nwc</th>\n",
       "      <th>rd_sale</th>\n",
       "      <th>adv_sale</th>\n",
       "      <th>staff_sale</th>\n",
       "      <th>accrual</th>\n",
       "      <th>ptb</th>\n",
       "      <th>FEMALE_PCT</th>\n",
       "      <th>FEMALE_PCT_LAST</th>\n",
       "      <th>x0_2012</th>\n",
       "      <th>x0_2013</th>\n",
       "      <th>x0_2014</th>\n",
       "      <th>x0_2015</th>\n",
       "      <th>x0_2016</th>\n",
       "      <th>x0_2017</th>\n",
       "      <th>x0_2018</th>\n",
       "      <th>x0_2019</th>\n",
       "      <th>x0_2020</th>\n",
       "      <th>x1_Automobiles &amp; Parts</th>\n",
       "      <th>x1_Banks</th>\n",
       "      <th>x1_Beverages</th>\n",
       "      <th>x1_Business Services</th>\n",
       "      <th>x1_Chemicals</th>\n",
       "      <th>x1_Clothing &amp; Personal Products</th>\n",
       "      <th>x1_Construction &amp; Building Materials</th>\n",
       "      <th>x1_Consumer Services</th>\n",
       "      <th>x1_Containers &amp; Packaging</th>\n",
       "      <th>x1_Diversified Industrials</th>\n",
       "      <th>x1_Education</th>\n",
       "      <th>x1_Electricity</th>\n",
       "      <th>x1_Electronic &amp; Electrical Equipment</th>\n",
       "      <th>x1_Engineering &amp; Machinery</th>\n",
       "      <th>x1_Food &amp; Drug Retailers</th>\n",
       "      <th>x1_Food Producers &amp; Processors</th>\n",
       "      <th>x1_Forestry &amp; Paper</th>\n",
       "      <th>x1_General Retailers</th>\n",
       "      <th>x1_Health</th>\n",
       "      <th>x1_Household Products</th>\n",
       "      <th>x1_Information Technology Hardware</th>\n",
       "      <th>x1_Insurance</th>\n",
       "      <th>x1_Leisure &amp; Hotels</th>\n",
       "      <th>x1_Leisure Goods</th>\n",
       "      <th>x1_Media &amp; Entertainment</th>\n",
       "      <th>x1_Mining</th>\n",
       "      <th>x1_Oil &amp; Gas</th>\n",
       "      <th>x1_Pharmaceuticals and Biotechnology</th>\n",
       "      <th>x1_Publishing</th>\n",
       "      <th>x1_Real Estate</th>\n",
       "      <th>x1_Renewable Energy</th>\n",
       "      <th>x1_Software &amp; Computer Services</th>\n",
       "      <th>x1_Speciality &amp; Other Finance</th>\n",
       "      <th>x1_Steel &amp; Other Metals</th>\n",
       "      <th>x1_Telecommunication Services</th>\n",
       "      <th>x1_Tobacco</th>\n",
       "      <th>x1_Transport</th>\n",
       "      <th>x1_Utilities - Other</th>\n",
       "      <th>x1_other_sector</th>\n",
       "      <th>x2_AR</th>\n",
       "      <th>x2_AZ</th>\n",
       "      <th>x2_BC</th>\n",
       "      <th>x2_CA</th>\n",
       "      <th>x2_CO</th>\n",
       "      <th>x2_CT</th>\n",
       "      <th>x2_DC</th>\n",
       "      <th>x2_DE</th>\n",
       "      <th>x2_FL</th>\n",
       "      <th>x2_GA</th>\n",
       "      <th>x2_HI</th>\n",
       "      <th>x2_IA</th>\n",
       "      <th>x2_ID</th>\n",
       "      <th>x2_IL</th>\n",
       "      <th>x2_IN</th>\n",
       "      <th>x2_KS</th>\n",
       "      <th>x2_KY</th>\n",
       "      <th>x2_LA</th>\n",
       "      <th>x2_MA</th>\n",
       "      <th>x2_MD</th>\n",
       "      <th>x2_ME</th>\n",
       "      <th>x2_MI</th>\n",
       "      <th>x2_MN</th>\n",
       "      <th>x2_MO</th>\n",
       "      <th>x2_MS</th>\n",
       "      <th>x2_MT</th>\n",
       "      <th>x2_NC</th>\n",
       "      <th>x2_ND</th>\n",
       "      <th>x2_NE</th>\n",
       "      <th>x2_NH</th>\n",
       "      <th>x2_NJ</th>\n",
       "      <th>x2_NM</th>\n",
       "      <th>x2_NV</th>\n",
       "      <th>x2_NY</th>\n",
       "      <th>x2_OH</th>\n",
       "      <th>x2_OK</th>\n",
       "      <th>x2_ON</th>\n",
       "      <th>x2_OR</th>\n",
       "      <th>x2_PA</th>\n",
       "      <th>x2_PR</th>\n",
       "      <th>x2_QC</th>\n",
       "      <th>x2_RI</th>\n",
       "      <th>x2_SC</th>\n",
       "      <th>x2_SD</th>\n",
       "      <th>x2_TN</th>\n",
       "      <th>x2_TX</th>\n",
       "      <th>x2_UNKOWN</th>\n",
       "      <th>x2_UT</th>\n",
       "      <th>x2_VA</th>\n",
       "      <th>x2_VT</th>\n",
       "      <th>x2_WA</th>\n",
       "      <th>x2_WI</th>\n",
       "      <th>x2_WV</th>\n",
       "      <th>x2_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>782.8336</td>\n",
       "      <td>366.785559</td>\n",
       "      <td>101.80</td>\n",
       "      <td>1.645198</td>\n",
       "      <td>4541.9580</td>\n",
       "      <td>0.2</td>\n",
       "      <td>55.6</td>\n",
       "      <td>4.615192</td>\n",
       "      <td>9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.313333</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>6.684615</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.213333</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2574.600000</td>\n",
       "      <td>17.734</td>\n",
       "      <td>0.859</td>\n",
       "      <td>11.823566</td>\n",
       "      <td>21.235623</td>\n",
       "      <td>21.50583</td>\n",
       "      <td>34.175679</td>\n",
       "      <td>33.543717</td>\n",
       "      <td>1.524717</td>\n",
       "      <td>16.239151</td>\n",
       "      <td>0.918275</td>\n",
       "      <td>0.056321</td>\n",
       "      <td>0.143981</td>\n",
       "      <td>0.115075</td>\n",
       "      <td>0.338151</td>\n",
       "      <td>0.084509</td>\n",
       "      <td>0.087226</td>\n",
       "      <td>0.168151</td>\n",
       "      <td>0.286868</td>\n",
       "      <td>0.187755</td>\n",
       "      <td>0.305979</td>\n",
       "      <td>0.343623</td>\n",
       "      <td>0.106472</td>\n",
       "      <td>0.343717</td>\n",
       "      <td>0.442604</td>\n",
       "      <td>0.25917</td>\n",
       "      <td>0.446755</td>\n",
       "      <td>0.630755</td>\n",
       "      <td>0.363245</td>\n",
       "      <td>0.412075</td>\n",
       "      <td>0.365377</td>\n",
       "      <td>0.058755</td>\n",
       "      <td>0.051531</td>\n",
       "      <td>0.213057</td>\n",
       "      <td>0.394038</td>\n",
       "      <td>0.30334</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>2.293075</td>\n",
       "      <td>0.12264</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>0.405415</td>\n",
       "      <td>1.03334</td>\n",
       "      <td>0.739472</td>\n",
       "      <td>0.270154</td>\n",
       "      <td>0.612755</td>\n",
       "      <td>7.196717</td>\n",
       "      <td>0.883434</td>\n",
       "      <td>0.546849</td>\n",
       "      <td>0.456189</td>\n",
       "      <td>2.156038</td>\n",
       "      <td>187.84806</td>\n",
       "      <td>290.9171</td>\n",
       "      <td>0.504208</td>\n",
       "      <td>1.285528</td>\n",
       "      <td>2.13234</td>\n",
       "      <td>63.170255</td>\n",
       "      <td>12.725981</td>\n",
       "      <td>1.479057</td>\n",
       "      <td>18.711434</td>\n",
       "      <td>12.762321</td>\n",
       "      <td>2.210755</td>\n",
       "      <td>4.239057</td>\n",
       "      <td>11.17266</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.029585</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.052623</td>\n",
       "      <td>1.372</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>782.8336</td>\n",
       "      <td>366.785559</td>\n",
       "      <td>101.80</td>\n",
       "      <td>1.645198</td>\n",
       "      <td>4541.9580</td>\n",
       "      <td>0.2</td>\n",
       "      <td>55.6</td>\n",
       "      <td>4.615192</td>\n",
       "      <td>9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.313333</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>6.684615</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.213333</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2574.600000</td>\n",
       "      <td>17.734</td>\n",
       "      <td>0.859</td>\n",
       "      <td>11.823566</td>\n",
       "      <td>21.235623</td>\n",
       "      <td>21.50583</td>\n",
       "      <td>34.175679</td>\n",
       "      <td>33.543717</td>\n",
       "      <td>1.524717</td>\n",
       "      <td>16.239151</td>\n",
       "      <td>0.918275</td>\n",
       "      <td>0.056321</td>\n",
       "      <td>0.143981</td>\n",
       "      <td>0.115075</td>\n",
       "      <td>0.338151</td>\n",
       "      <td>0.084509</td>\n",
       "      <td>0.087226</td>\n",
       "      <td>0.168151</td>\n",
       "      <td>0.286868</td>\n",
       "      <td>0.187755</td>\n",
       "      <td>0.305979</td>\n",
       "      <td>0.343623</td>\n",
       "      <td>0.106472</td>\n",
       "      <td>0.343717</td>\n",
       "      <td>0.442604</td>\n",
       "      <td>0.25917</td>\n",
       "      <td>0.446755</td>\n",
       "      <td>0.630755</td>\n",
       "      <td>0.363245</td>\n",
       "      <td>0.412075</td>\n",
       "      <td>0.365377</td>\n",
       "      <td>0.058755</td>\n",
       "      <td>0.051531</td>\n",
       "      <td>0.213057</td>\n",
       "      <td>0.394038</td>\n",
       "      <td>0.30334</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>2.293075</td>\n",
       "      <td>0.12264</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>0.405415</td>\n",
       "      <td>1.03334</td>\n",
       "      <td>0.739472</td>\n",
       "      <td>0.270154</td>\n",
       "      <td>0.612755</td>\n",
       "      <td>7.196717</td>\n",
       "      <td>0.883434</td>\n",
       "      <td>0.546849</td>\n",
       "      <td>0.456189</td>\n",
       "      <td>2.156038</td>\n",
       "      <td>187.84806</td>\n",
       "      <td>290.9171</td>\n",
       "      <td>0.504208</td>\n",
       "      <td>1.285528</td>\n",
       "      <td>2.13234</td>\n",
       "      <td>63.170255</td>\n",
       "      <td>12.725981</td>\n",
       "      <td>1.479057</td>\n",
       "      <td>18.711434</td>\n",
       "      <td>12.762321</td>\n",
       "      <td>2.210755</td>\n",
       "      <td>4.239057</td>\n",
       "      <td>11.17266</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.029585</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.052623</td>\n",
       "      <td>1.372</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>904.0280</td>\n",
       "      <td>298.014814</td>\n",
       "      <td>28.49</td>\n",
       "      <td>47.697865</td>\n",
       "      <td>8377.5166</td>\n",
       "      <td>0.3</td>\n",
       "      <td>53.8</td>\n",
       "      <td>4.764452</td>\n",
       "      <td>9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>9.233333</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>6.646667</td>\n",
       "      <td>4.9</td>\n",
       "      <td>7.744444</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.625</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.562500</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2461.777778</td>\n",
       "      <td>21.509</td>\n",
       "      <td>0.659</td>\n",
       "      <td>9.751000</td>\n",
       "      <td>17.687000</td>\n",
       "      <td>17.80800</td>\n",
       "      <td>17.869000</td>\n",
       "      <td>17.869000</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>7.094000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.07600</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>1.624000</td>\n",
       "      <td>0.09700</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.26700</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.303643</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>2.137000</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>6.55200</td>\n",
       "      <td>8.0200</td>\n",
       "      <td>0.534000</td>\n",
       "      <td>1.208000</td>\n",
       "      <td>1.93700</td>\n",
       "      <td>26.711000</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>2.023000</td>\n",
       "      <td>17.101000</td>\n",
       "      <td>8.836000</td>\n",
       "      <td>3.307000</td>\n",
       "      <td>4.192000</td>\n",
       "      <td>6.58500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>1.539</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CEO_FEMALE  EXECDIR_COUNT  AVG_SALARY  STD_SALARY  AVG_SALPCT  STD_SALPCT  \\\n",
       "0           1              2    782.8336  366.785559      101.80    1.645198   \n",
       "1           1              2    782.8336  366.785559      101.80    1.645198   \n",
       "2           1              2    904.0280  298.014814       28.49   47.697865   \n",
       "\n",
       "   AVG_TOTAL_COMP  NationalityMix  AVG_AGE   STD_AGE  Length_term  STDEVAge  \\\n",
       "0       4541.9580             0.2     55.6  4.615192            9       4.5   \n",
       "1       4541.9580             0.2     55.6  4.615192            9       4.5   \n",
       "2       8377.5166             0.3     53.8  4.764452            9       4.9   \n",
       "\n",
       "   TimeRetirement  TimeRole   TimeBrd  STDEVTimeBrd  TimeInCo  STDEVTimeInCo  \\\n",
       "0        9.313333  4.900000  6.684615           4.3  6.213333            4.3   \n",
       "1        9.313333  4.900000  6.684615           4.3  6.213333            4.3   \n",
       "2        9.233333  4.566667  6.646667           4.9  7.744444            4.6   \n",
       "\n",
       "   TotNoLstdBrd  STDEVTotNoLstdBrd  TotNoUnLstdBrd  TotCurrNoLstdBrd  \\\n",
       "0         3.500                1.0        4.285714          2.307692   \n",
       "1         3.500                1.0        4.285714          2.307692   \n",
       "2         3.625                1.6        4.562500          2.437500   \n",
       "\n",
       "   TotCurrNoUnLstdBrd   NoQuals  STDEVNoQuals  Succession  NetworkSize  \\\n",
       "0            2.000000  2.200000           1.0         0.2  2574.600000   \n",
       "1            2.000000  2.200000           1.0         0.2  2574.600000   \n",
       "2            2.571429  2.222222           0.9         0.2  2461.777778   \n",
       "\n",
       "    CAPEI     bm        evm  pe_op_basic  pe_op_dil     pe_exi     pe_inc  \\\n",
       "0  17.734  0.859  11.823566    21.235623   21.50583  34.175679  33.543717   \n",
       "1  17.734  0.859  11.823566    21.235623   21.50583  34.175679  33.543717   \n",
       "2  21.509  0.659   9.751000    17.687000   17.80800  17.869000  17.869000   \n",
       "\n",
       "         ps        pcf       dpr       npm     opmbd     opmad       gpm  \\\n",
       "0  1.524717  16.239151  0.918275  0.056321  0.143981  0.115075  0.338151   \n",
       "1  1.524717  16.239151  0.918275  0.056321  0.143981  0.115075  0.338151   \n",
       "2  0.396000   7.094000  0.310000  0.023000  0.043000  0.033000  0.063000   \n",
       "\n",
       "       ptpm       cfm       roa       roe      roce    efftax  aftret_eq  \\\n",
       "0  0.084509  0.087226  0.168151  0.286868  0.187755  0.305979   0.343623   \n",
       "1  0.084509  0.087226  0.168151  0.286868  0.187755  0.305979   0.343623   \n",
       "2  0.033000  0.033000  0.088000  0.090000  0.106000  0.331000   0.096000   \n",
       "\n",
       "   aftret_invcapx  aftret_equity  pretret_noa  pretret_earnat     GProf  \\\n",
       "0        0.106472       0.343717     0.442604         0.25917  0.446755   \n",
       "1        0.106472       0.343717     0.442604         0.25917  0.446755   \n",
       "2        0.085000       0.096000     0.122000         0.07600  0.128000   \n",
       "\n",
       "   equity_invcap  debt_invcap  totdebt_invcap  capital_ratio  int_debt  \\\n",
       "0       0.630755     0.363245        0.412075       0.365377  0.058755   \n",
       "1       0.630755     0.363245        0.412075       0.365377  0.058755   \n",
       "2       0.789000     0.210000        0.232000       0.210000  0.065000   \n",
       "\n",
       "   int_totdebt   cash_lt  invt_act  rect_act   debt_at  debt_ebitda  \\\n",
       "0     0.051531  0.213057  0.394038   0.30334  0.276189     2.293075   \n",
       "1     0.051531  0.213057  0.394038   0.30334  0.276189     2.293075   \n",
       "2     0.058000  0.339000  0.376000   0.18600  0.142000     1.624000   \n",
       "\n",
       "   short_debt  curr_debt   lt_debt  profit_lct   ocf_lct  cash_debt   fcf_ocf  \\\n",
       "0     0.12264   0.396038  0.405415     1.03334  0.739472   0.270154  0.612755   \n",
       "1     0.12264   0.396038  0.405415     1.03334  0.739472   0.270154  0.612755   \n",
       "2     0.09700   0.635000  0.248000     0.26700  0.345000   0.303643  0.818000   \n",
       "\n",
       "   lt_ppent   dltt_be  debt_assets  debt_capital  de_ratio     intcov  \\\n",
       "0  7.196717  0.883434     0.546849      0.456189  2.156038  187.84806   \n",
       "1  7.196717  0.883434     0.546849      0.456189  2.156038  187.84806   \n",
       "2  2.137000  0.247000     0.516000      0.422000  1.070000    6.55200   \n",
       "\n",
       "   intcov_ratio  cash_ratio  quick_ratio  curr_ratio  cash_conversion  \\\n",
       "0      290.9171    0.504208     1.285528     2.13234        63.170255   \n",
       "1      290.9171    0.504208     1.285528     2.13234        63.170255   \n",
       "2        8.0200    0.534000     1.208000     1.93700        26.711000   \n",
       "\n",
       "    inv_turn   at_turn  rect_turn   pay_turn  sale_invcap  sale_equity  \\\n",
       "0  12.725981  1.479057  18.711434  12.762321     2.210755     4.239057   \n",
       "1  12.725981  1.479057  18.711434  12.762321     2.210755     4.239057   \n",
       "2   7.930000  2.023000  17.101000   8.836000     3.307000     4.192000   \n",
       "\n",
       "   sale_nwc   rd_sale  adv_sale  staff_sale   accrual    ptb  FEMALE_PCT  \\\n",
       "0  11.17266  0.006698  0.029585    0.002019  0.052623  1.372         0.2   \n",
       "1  11.17266  0.006698  0.029585    0.002019  0.052623  1.372         0.2   \n",
       "2   6.58500  0.001000  0.000000    0.000000  0.067000  1.539         0.2   \n",
       "\n",
       "   FEMALE_PCT_LAST  x0_2012  x0_2013  x0_2014  x0_2015  x0_2016  x0_2017  \\\n",
       "0         0.142857        0        1        0        0        0        0   \n",
       "1         0.142857        0        1        0        0        0        0   \n",
       "2         0.200000        0        0        1        0        0        0   \n",
       "\n",
       "   x0_2018  x0_2019  x0_2020  x1_Automobiles & Parts  x1_Banks  x1_Beverages  \\\n",
       "0        0        0        0                       0         0             0   \n",
       "1        0        0        0                       0         0             0   \n",
       "2        0        0        0                       0         0             0   \n",
       "\n",
       "   x1_Business Services  x1_Chemicals  x1_Clothing & Personal Products  \\\n",
       "0                     0             0                                0   \n",
       "1                     0             0                                0   \n",
       "2                     0             0                                0   \n",
       "\n",
       "   x1_Construction & Building Materials  x1_Consumer Services  \\\n",
       "0                                     0                     0   \n",
       "1                                     0                     0   \n",
       "2                                     0                     0   \n",
       "\n",
       "   x1_Containers & Packaging  x1_Diversified Industrials  x1_Education  \\\n",
       "0                          0                           0             0   \n",
       "1                          0                           0             0   \n",
       "2                          0                           0             0   \n",
       "\n",
       "   x1_Electricity  x1_Electronic & Electrical Equipment  \\\n",
       "0               0                                     0   \n",
       "1               0                                     0   \n",
       "2               0                                     0   \n",
       "\n",
       "   x1_Engineering & Machinery  x1_Food & Drug Retailers  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "\n",
       "   x1_Food Producers & Processors  x1_Forestry & Paper  x1_General Retailers  \\\n",
       "0                               1                    0                     0   \n",
       "1                               1                    0                     0   \n",
       "2                               1                    0                     0   \n",
       "\n",
       "   x1_Health  x1_Household Products  x1_Information Technology Hardware  \\\n",
       "0          0                      0                                   0   \n",
       "1          0                      0                                   0   \n",
       "2          0                      0                                   0   \n",
       "\n",
       "   x1_Insurance  x1_Leisure & Hotels  x1_Leisure Goods  \\\n",
       "0             0                    0                 0   \n",
       "1             0                    0                 0   \n",
       "2             0                    0                 0   \n",
       "\n",
       "   x1_Media & Entertainment  x1_Mining  x1_Oil & Gas  \\\n",
       "0                         0          0             0   \n",
       "1                         0          0             0   \n",
       "2                         0          0             0   \n",
       "\n",
       "   x1_Pharmaceuticals and Biotechnology  x1_Publishing  x1_Real Estate  \\\n",
       "0                                     0              0               0   \n",
       "1                                     0              0               0   \n",
       "2                                     0              0               0   \n",
       "\n",
       "   x1_Renewable Energy  x1_Software & Computer Services  \\\n",
       "0                    0                                0   \n",
       "1                    0                                0   \n",
       "2                    0                                0   \n",
       "\n",
       "   x1_Speciality & Other Finance  x1_Steel & Other Metals  \\\n",
       "0                              0                        0   \n",
       "1                              0                        0   \n",
       "2                              0                        0   \n",
       "\n",
       "   x1_Telecommunication Services  x1_Tobacco  x1_Transport  \\\n",
       "0                              0           0             0   \n",
       "1                              0           0             0   \n",
       "2                              0           0             0   \n",
       "\n",
       "   x1_Utilities - Other  x1_other_sector  x2_AR  x2_AZ  x2_BC  x2_CA  x2_CO  \\\n",
       "0                     0                0      0      0      0      0      0   \n",
       "1                     0                0      0      0      0      0      0   \n",
       "2                     0                0      0      0      0      0      0   \n",
       "\n",
       "   x2_CT  x2_DC  x2_DE  x2_FL  x2_GA  x2_HI  x2_IA  x2_ID  x2_IL  x2_IN  \\\n",
       "0      0      0      0      0      0      0      0      0      1      0   \n",
       "1      0      0      0      0      0      0      0      0      1      0   \n",
       "2      0      0      0      0      0      0      0      0      1      0   \n",
       "\n",
       "   x2_KS  x2_KY  x2_LA  x2_MA  x2_MD  x2_ME  x2_MI  x2_MN  x2_MO  x2_MS  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0   \n",
       "1      0      0      0      0      0      0      0      0      0      0   \n",
       "2      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   x2_MT  x2_NC  x2_ND  x2_NE  x2_NH  x2_NJ  x2_NM  x2_NV  x2_NY  x2_OH  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0   \n",
       "1      0      0      0      0      0      0      0      0      0      0   \n",
       "2      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   x2_OK  x2_ON  x2_OR  x2_PA  x2_PR  x2_QC  x2_RI  x2_SC  x2_SD  x2_TN  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0   \n",
       "1      0      0      0      0      0      0      0      0      0      0   \n",
       "2      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   x2_TX  x2_UNKOWN  x2_UT  x2_VA  x2_VT  x2_WA  x2_WI  x2_WV  x2_WY  \n",
       "0      0          0      0      0      0      0      0      0      0  \n",
       "1      0          0      0      0      0      0      0      0      0  \n",
       "2      0          0      0      0      0      0      0      0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some infinite values that can cause problem later; thus we replace inf values with NaN values\n",
    "data = data[data.replace([np.inf, -np.inf], np.nan).notnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CEO_FEMALE                              0\n",
       "EXECDIR_COUNT                           0\n",
       "AVG_SALARY                              0\n",
       "STD_SALARY                              0\n",
       "AVG_SALPCT                              0\n",
       "STD_SALPCT                              0\n",
       "AVG_TOTAL_COMP                          0\n",
       "NationalityMix                          0\n",
       "AVG_AGE                                 0\n",
       "STD_AGE                                 0\n",
       "Length_term                             0\n",
       "STDEVAge                                0\n",
       "TimeRetirement                          0\n",
       "TimeRole                                0\n",
       "TimeBrd                                 0\n",
       "STDEVTimeBrd                            0\n",
       "TimeInCo                                0\n",
       "STDEVTimeInCo                           0\n",
       "TotNoLstdBrd                            0\n",
       "STDEVTotNoLstdBrd                       0\n",
       "TotNoUnLstdBrd                          0\n",
       "TotCurrNoLstdBrd                        0\n",
       "TotCurrNoUnLstdBrd                      0\n",
       "NoQuals                                 0\n",
       "STDEVNoQuals                            0\n",
       "Succession                              0\n",
       "NetworkSize                             0\n",
       "CAPEI                                   0\n",
       "bm                                      0\n",
       "evm                                     0\n",
       "pe_op_basic                             0\n",
       "pe_op_dil                               0\n",
       "pe_exi                                  0\n",
       "pe_inc                                  0\n",
       "ps                                      0\n",
       "pcf                                     0\n",
       "dpr                                     0\n",
       "npm                                     0\n",
       "opmbd                                   0\n",
       "opmad                                   0\n",
       "gpm                                     0\n",
       "ptpm                                    0\n",
       "cfm                                     0\n",
       "roa                                     0\n",
       "roe                                     0\n",
       "roce                                    0\n",
       "efftax                                  0\n",
       "aftret_eq                               0\n",
       "aftret_invcapx                          0\n",
       "aftret_equity                           0\n",
       "pretret_noa                             0\n",
       "pretret_earnat                          0\n",
       "GProf                                   0\n",
       "equity_invcap                           0\n",
       "debt_invcap                             0\n",
       "totdebt_invcap                          0\n",
       "capital_ratio                           0\n",
       "int_debt                                0\n",
       "int_totdebt                             0\n",
       "cash_lt                                 0\n",
       "invt_act                                0\n",
       "rect_act                                0\n",
       "debt_at                                 0\n",
       "debt_ebitda                             0\n",
       "short_debt                              0\n",
       "curr_debt                               0\n",
       "lt_debt                                 0\n",
       "profit_lct                              0\n",
       "ocf_lct                                 0\n",
       "cash_debt                               0\n",
       "fcf_ocf                                 0\n",
       "lt_ppent                                0\n",
       "dltt_be                                 0\n",
       "debt_assets                             0\n",
       "debt_capital                            0\n",
       "de_ratio                                0\n",
       "intcov                                  0\n",
       "intcov_ratio                            0\n",
       "cash_ratio                              0\n",
       "quick_ratio                             0\n",
       "curr_ratio                              0\n",
       "cash_conversion                         0\n",
       "inv_turn                                0\n",
       "at_turn                                 0\n",
       "rect_turn                               0\n",
       "pay_turn                                0\n",
       "sale_invcap                             0\n",
       "sale_equity                             0\n",
       "sale_nwc                                0\n",
       "rd_sale                                 0\n",
       "adv_sale                                0\n",
       "staff_sale                              0\n",
       "accrual                                 0\n",
       "ptb                                     0\n",
       "FEMALE_PCT                              0\n",
       "FEMALE_PCT_LAST                         0\n",
       "x0_2012                                 0\n",
       "x0_2013                                 0\n",
       "x0_2014                                 0\n",
       "x0_2015                                 0\n",
       "x0_2016                                 0\n",
       "x0_2017                                 0\n",
       "x0_2018                                 0\n",
       "x0_2019                                 0\n",
       "x0_2020                                 0\n",
       "x1_Automobiles & Parts                  0\n",
       "x1_Banks                                0\n",
       "x1_Beverages                            0\n",
       "x1_Business Services                    0\n",
       "x1_Chemicals                            0\n",
       "x1_Clothing & Personal Products         0\n",
       "x1_Construction & Building Materials    0\n",
       "x1_Consumer Services                    0\n",
       "x1_Containers & Packaging               0\n",
       "x1_Diversified Industrials              0\n",
       "x1_Education                            0\n",
       "x1_Electricity                          0\n",
       "x1_Electronic & Electrical Equipment    0\n",
       "x1_Engineering & Machinery              0\n",
       "x1_Food & Drug Retailers                0\n",
       "x1_Food Producers & Processors          0\n",
       "x1_Forestry & Paper                     0\n",
       "x1_General Retailers                    0\n",
       "x1_Health                               0\n",
       "x1_Household Products                   0\n",
       "x1_Information Technology Hardware      0\n",
       "x1_Insurance                            0\n",
       "x1_Leisure & Hotels                     0\n",
       "x1_Leisure Goods                        0\n",
       "x1_Media & Entertainment                0\n",
       "x1_Mining                               0\n",
       "x1_Oil & Gas                            0\n",
       "x1_Pharmaceuticals and Biotechnology    0\n",
       "x1_Publishing                           0\n",
       "x1_Real Estate                          0\n",
       "x1_Renewable Energy                     0\n",
       "x1_Software & Computer Services         0\n",
       "x1_Speciality & Other Finance           0\n",
       "x1_Steel & Other Metals                 0\n",
       "x1_Telecommunication Services           0\n",
       "x1_Tobacco                              0\n",
       "x1_Transport                            0\n",
       "x1_Utilities - Other                    0\n",
       "x1_other_sector                         0\n",
       "x2_AR                                   0\n",
       "x2_AZ                                   0\n",
       "x2_BC                                   0\n",
       "x2_CA                                   0\n",
       "x2_CO                                   0\n",
       "x2_CT                                   0\n",
       "x2_DC                                   0\n",
       "x2_DE                                   0\n",
       "x2_FL                                   0\n",
       "x2_GA                                   0\n",
       "x2_HI                                   0\n",
       "x2_IA                                   0\n",
       "x2_ID                                   0\n",
       "x2_IL                                   0\n",
       "x2_IN                                   0\n",
       "x2_KS                                   0\n",
       "x2_KY                                   0\n",
       "x2_LA                                   0\n",
       "x2_MA                                   0\n",
       "x2_MD                                   0\n",
       "x2_ME                                   0\n",
       "x2_MI                                   0\n",
       "x2_MN                                   0\n",
       "x2_MO                                   0\n",
       "x2_MS                                   0\n",
       "x2_MT                                   0\n",
       "x2_NC                                   0\n",
       "x2_ND                                   0\n",
       "x2_NE                                   0\n",
       "x2_NH                                   0\n",
       "x2_NJ                                   0\n",
       "x2_NM                                   0\n",
       "x2_NV                                   0\n",
       "x2_NY                                   0\n",
       "x2_OH                                   0\n",
       "x2_OK                                   0\n",
       "x2_ON                                   0\n",
       "x2_OR                                   0\n",
       "x2_PA                                   0\n",
       "x2_PR                                   0\n",
       "x2_QC                                   0\n",
       "x2_RI                                   0\n",
       "x2_SC                                   0\n",
       "x2_SD                                   0\n",
       "x2_TN                                   0\n",
       "x2_TX                                   0\n",
       "x2_UNKOWN                               0\n",
       "x2_UT                                   0\n",
       "x2_VA                                   0\n",
       "x2_VT                                   0\n",
       "x2_WA                                   0\n",
       "x2_WI                                   0\n",
       "x2_WV                                   0\n",
       "x2_WY                                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for EDA\n",
    "import seaborn as sns #visualisation\n",
    "import matplotlib.pyplot as plt #visualisation\n",
    "%matplotlib inline \n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numcols contain the list of all columns that contain either float or integer values\n",
    "numcols = data.select_dtypes(include=['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Density plot\n",
    "#for i, col in enumerate(numcols):\n",
    "    #plt.figure(i)\n",
    "    #sns.distplot(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram plot\n",
    "#for i, col in enumerate(numcols):\n",
    "    #plt.figure(i)\n",
    "    #data[[col]].plot.hist(bins = 10, title = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe called 'num_data', which contains only columns that are either integer or float\n",
    "num_data = data[data.columns.intersection(numcols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Finding the relations between the variables.\n",
    "c= num_data.corr().abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\")\n",
    "corr = pd.DataFrame(so.tail(1000), columns = ['correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Absolute Correlations\n",
      "npm                ptpm                  0.999734\n",
      "opmbd              opmad                 0.999290\n",
      "npm                opmad                 0.997235\n",
      "aftret_eq          aftret_equity         0.996749\n",
      "opmad              ptpm                  0.996706\n",
      "npm                opmbd                 0.996045\n",
      "opmbd              ptpm                  0.994756\n",
      "                   gpm                   0.993895\n",
      "opmad              gpm                   0.993546\n",
      "npm                gpm                   0.990655\n",
      "equity_invcap      debt_invcap           0.990117\n",
      "gpm                ptpm                  0.989419\n",
      "de_ratio           sale_equity           0.984575\n",
      "opmbd              cfm                   0.981713\n",
      "pe_op_basic        pe_op_dil             0.978368\n",
      "npm                cfm                   0.976376\n",
      "opmad              cfm                   0.975304\n",
      "gpm                cfm                   0.975139\n",
      "ptpm               cfm                   0.971712\n",
      "AVG_SALPCT         STD_SALPCT            0.967782\n",
      "cash_ratio         quick_ratio           0.964021\n",
      "quick_ratio        curr_ratio            0.957143\n",
      "rd_sale            staff_sale            0.946891\n",
      "STDEVTimeBrd       STDEVTimeInCo         0.929907\n",
      "intcov             intcov_ratio          0.927727\n",
      "TimeBrd            TimeInCo              0.922705\n",
      "cash_ratio         curr_ratio            0.909024\n",
      "profit_lct         ocf_lct               0.884132\n",
      "TimeRole           TimeBrd               0.877972\n",
      "debt_invcap        capital_ratio         0.876447\n",
      "equity_invcap      capital_ratio         0.875386\n",
      "debt_invcap        totdebt_invcap        0.853242\n",
      "equity_invcap      totdebt_invcap        0.846922\n",
      "FEMALE_PCT         FEMALE_PCT_LAST       0.842876\n",
      "pe_exi             pe_inc                0.826182\n",
      "TimeInCo           STDEVTimeInCo         0.810014\n",
      "cash_lt            cash_ratio            0.793808\n",
      "TimeRole           TimeInCo              0.793474\n",
      "TimeBrd            STDEVTimeBrd          0.793178\n",
      "TotNoLstdBrd       TotCurrNoLstdBrd      0.789498\n",
      "                   STDEVTotNoLstdBrd     0.788003\n",
      "STDEVTimeBrd       TimeInCo              0.776570\n",
      "debt_at            lt_debt               0.773031\n",
      "cash_lt            quick_ratio           0.770439\n",
      "AVG_SALARY         STD_SALARY            0.746223\n",
      "cash_lt            curr_ratio            0.739629\n",
      "TimeBrd            STDEVTimeInCo         0.733219\n",
      "totdebt_invcap     capital_ratio         0.727552\n",
      "cfm                rd_sale               0.704066\n",
      "ps                 cfm                   0.693559\n",
      "curr_debt          lt_debt               0.693017\n",
      "cfm                staff_sale            0.686945\n",
      "TimeRetirement     Succession            0.670003\n",
      "debt_at            debt_assets           0.664045\n",
      "roa                pretret_earnat        0.660262\n",
      "ps                 rd_sale               0.636306\n",
      "STDEVAge           Succession            0.629490\n",
      "debt_invcap        debt_at               0.628779\n",
      "equity_invcap      debt_at               0.622944\n",
      "opmbd              rd_sale               0.613553\n",
      "TotNoUnLstdBrd     TotCurrNoUnLstdBrd    0.610443\n",
      "ps                 staff_sale            0.597531\n",
      "                   opmbd                 0.596101\n",
      "                   npm                   0.595002\n",
      "gpm                rd_sale               0.594773\n",
      "opmad              rd_sale               0.594126\n",
      "gpm                staff_sale            0.593851\n",
      "opmbd              staff_sale            0.593006\n",
      "STDEVTotNoLstdBrd  TotCurrNoLstdBrd      0.591537\n",
      "TimeRole           STDEVTimeBrd          0.590889\n",
      "ps                 gpm                   0.588381\n",
      "                   ptpm                  0.585275\n",
      "debt_invcap        debt_assets           0.583473\n",
      "equity_invcap      debt_assets           0.582301\n",
      "ps                 opmad                 0.580309\n",
      "npm                rd_sale               0.579016\n",
      "roa                GProf                 0.577324\n",
      "opmad              staff_sale            0.575807\n",
      "npm                staff_sale            0.565307\n",
      "ptpm               rd_sale               0.565093\n",
      "debt_at            curr_debt             0.557565\n",
      "ptpm               staff_sale            0.552347\n",
      "roa                profit_lct            0.533030\n",
      "TimeRole           STDEVTimeInCo         0.532883\n",
      "at_turn            sale_invcap           0.515594\n",
      "TimeRetirement     TimeBrd               0.514336\n",
      "GProf              at_turn               0.503048\n",
      "totdebt_invcap     debt_assets           0.497826\n",
      "pretret_earnat     profit_lct            0.495752\n",
      "TimeRetirement     TimeRole              0.494015\n",
      "ocf_lct            cash_debt             0.490297\n",
      "totdebt_invcap     debt_at               0.489455\n",
      "roa                cash_debt             0.482427\n",
      "TimeRetirement     TimeInCo              0.477042\n",
      "totdebt_invcap     sale_invcap           0.472043\n",
      "capital_ratio      debt_at               0.463301\n",
      "cash_lt            debt_assets           0.454666\n",
      "curr_debt          debt_assets           0.452117\n",
      "profit_lct         cash_debt             0.447315\n",
      "AVG_AGE            TimeRetirement        0.440130\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# List highest correlation pairs from a correlation matrix (while avoiding duplicates and self-correlations)\n",
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=100):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(num_data, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CEO_FEMALE</th>\n",
       "      <th>EXECDIR_COUNT</th>\n",
       "      <th>AVG_SALARY</th>\n",
       "      <th>STD_SALARY</th>\n",
       "      <th>AVG_SALPCT</th>\n",
       "      <th>STD_SALPCT</th>\n",
       "      <th>AVG_TOTAL_COMP</th>\n",
       "      <th>NationalityMix</th>\n",
       "      <th>AVG_AGE</th>\n",
       "      <th>STD_AGE</th>\n",
       "      <th>Length_term</th>\n",
       "      <th>STDEVAge</th>\n",
       "      <th>TimeRetirement</th>\n",
       "      <th>TimeRole</th>\n",
       "      <th>TimeBrd</th>\n",
       "      <th>STDEVTimeBrd</th>\n",
       "      <th>TimeInCo</th>\n",
       "      <th>STDEVTimeInCo</th>\n",
       "      <th>TotNoLstdBrd</th>\n",
       "      <th>STDEVTotNoLstdBrd</th>\n",
       "      <th>TotNoUnLstdBrd</th>\n",
       "      <th>TotCurrNoLstdBrd</th>\n",
       "      <th>TotCurrNoUnLstdBrd</th>\n",
       "      <th>NoQuals</th>\n",
       "      <th>STDEVNoQuals</th>\n",
       "      <th>Succession</th>\n",
       "      <th>NetworkSize</th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>bm</th>\n",
       "      <th>evm</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>dpr</th>\n",
       "      <th>npm</th>\n",
       "      <th>opmbd</th>\n",
       "      <th>opmad</th>\n",
       "      <th>gpm</th>\n",
       "      <th>ptpm</th>\n",
       "      <th>cfm</th>\n",
       "      <th>roa</th>\n",
       "      <th>roe</th>\n",
       "      <th>roce</th>\n",
       "      <th>efftax</th>\n",
       "      <th>aftret_eq</th>\n",
       "      <th>aftret_invcapx</th>\n",
       "      <th>aftret_equity</th>\n",
       "      <th>pretret_noa</th>\n",
       "      <th>pretret_earnat</th>\n",
       "      <th>GProf</th>\n",
       "      <th>equity_invcap</th>\n",
       "      <th>debt_invcap</th>\n",
       "      <th>totdebt_invcap</th>\n",
       "      <th>capital_ratio</th>\n",
       "      <th>int_debt</th>\n",
       "      <th>int_totdebt</th>\n",
       "      <th>cash_lt</th>\n",
       "      <th>invt_act</th>\n",
       "      <th>rect_act</th>\n",
       "      <th>debt_at</th>\n",
       "      <th>debt_ebitda</th>\n",
       "      <th>short_debt</th>\n",
       "      <th>curr_debt</th>\n",
       "      <th>lt_debt</th>\n",
       "      <th>profit_lct</th>\n",
       "      <th>ocf_lct</th>\n",
       "      <th>cash_debt</th>\n",
       "      <th>fcf_ocf</th>\n",
       "      <th>lt_ppent</th>\n",
       "      <th>dltt_be</th>\n",
       "      <th>debt_assets</th>\n",
       "      <th>debt_capital</th>\n",
       "      <th>de_ratio</th>\n",
       "      <th>intcov</th>\n",
       "      <th>intcov_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>curr_ratio</th>\n",
       "      <th>cash_conversion</th>\n",
       "      <th>inv_turn</th>\n",
       "      <th>at_turn</th>\n",
       "      <th>rect_turn</th>\n",
       "      <th>pay_turn</th>\n",
       "      <th>sale_invcap</th>\n",
       "      <th>sale_equity</th>\n",
       "      <th>sale_nwc</th>\n",
       "      <th>rd_sale</th>\n",
       "      <th>adv_sale</th>\n",
       "      <th>staff_sale</th>\n",
       "      <th>accrual</th>\n",
       "      <th>ptb</th>\n",
       "      <th>FEMALE_PCT</th>\n",
       "      <th>FEMALE_PCT_LAST</th>\n",
       "      <th>x0_2012</th>\n",
       "      <th>x0_2013</th>\n",
       "      <th>x0_2014</th>\n",
       "      <th>x0_2015</th>\n",
       "      <th>x0_2016</th>\n",
       "      <th>x0_2017</th>\n",
       "      <th>x0_2018</th>\n",
       "      <th>x0_2019</th>\n",
       "      <th>x0_2020</th>\n",
       "      <th>x1_Automobiles &amp; Parts</th>\n",
       "      <th>x1_Banks</th>\n",
       "      <th>x1_Beverages</th>\n",
       "      <th>x1_Business Services</th>\n",
       "      <th>x1_Chemicals</th>\n",
       "      <th>x1_Clothing &amp; Personal Products</th>\n",
       "      <th>x1_Construction &amp; Building Materials</th>\n",
       "      <th>x1_Consumer Services</th>\n",
       "      <th>x1_Containers &amp; Packaging</th>\n",
       "      <th>x1_Diversified Industrials</th>\n",
       "      <th>x1_Education</th>\n",
       "      <th>x1_Electricity</th>\n",
       "      <th>x1_Electronic &amp; Electrical Equipment</th>\n",
       "      <th>x1_Engineering &amp; Machinery</th>\n",
       "      <th>x1_Food &amp; Drug Retailers</th>\n",
       "      <th>x1_Food Producers &amp; Processors</th>\n",
       "      <th>x1_Forestry &amp; Paper</th>\n",
       "      <th>x1_General Retailers</th>\n",
       "      <th>x1_Health</th>\n",
       "      <th>x1_Household Products</th>\n",
       "      <th>x1_Information Technology Hardware</th>\n",
       "      <th>x1_Insurance</th>\n",
       "      <th>x1_Leisure &amp; Hotels</th>\n",
       "      <th>x1_Leisure Goods</th>\n",
       "      <th>x1_Media &amp; Entertainment</th>\n",
       "      <th>x1_Mining</th>\n",
       "      <th>x1_Oil &amp; Gas</th>\n",
       "      <th>x1_Pharmaceuticals and Biotechnology</th>\n",
       "      <th>x1_Publishing</th>\n",
       "      <th>x1_Real Estate</th>\n",
       "      <th>x1_Renewable Energy</th>\n",
       "      <th>x1_Software &amp; Computer Services</th>\n",
       "      <th>x1_Speciality &amp; Other Finance</th>\n",
       "      <th>x1_Steel &amp; Other Metals</th>\n",
       "      <th>x1_Telecommunication Services</th>\n",
       "      <th>x1_Tobacco</th>\n",
       "      <th>x1_Transport</th>\n",
       "      <th>x1_Utilities - Other</th>\n",
       "      <th>x1_other_sector</th>\n",
       "      <th>x2_AR</th>\n",
       "      <th>x2_AZ</th>\n",
       "      <th>x2_BC</th>\n",
       "      <th>x2_CA</th>\n",
       "      <th>x2_CO</th>\n",
       "      <th>x2_CT</th>\n",
       "      <th>x2_DC</th>\n",
       "      <th>x2_DE</th>\n",
       "      <th>x2_FL</th>\n",
       "      <th>x2_GA</th>\n",
       "      <th>x2_HI</th>\n",
       "      <th>x2_IA</th>\n",
       "      <th>x2_ID</th>\n",
       "      <th>x2_IL</th>\n",
       "      <th>x2_IN</th>\n",
       "      <th>x2_KS</th>\n",
       "      <th>x2_KY</th>\n",
       "      <th>x2_LA</th>\n",
       "      <th>x2_MA</th>\n",
       "      <th>x2_MD</th>\n",
       "      <th>x2_ME</th>\n",
       "      <th>x2_MI</th>\n",
       "      <th>x2_MN</th>\n",
       "      <th>x2_MO</th>\n",
       "      <th>x2_MS</th>\n",
       "      <th>x2_MT</th>\n",
       "      <th>x2_NC</th>\n",
       "      <th>x2_ND</th>\n",
       "      <th>x2_NE</th>\n",
       "      <th>x2_NH</th>\n",
       "      <th>x2_NJ</th>\n",
       "      <th>x2_NM</th>\n",
       "      <th>x2_NV</th>\n",
       "      <th>x2_NY</th>\n",
       "      <th>x2_OH</th>\n",
       "      <th>x2_OK</th>\n",
       "      <th>x2_ON</th>\n",
       "      <th>x2_OR</th>\n",
       "      <th>x2_PA</th>\n",
       "      <th>x2_PR</th>\n",
       "      <th>x2_QC</th>\n",
       "      <th>x2_RI</th>\n",
       "      <th>x2_SC</th>\n",
       "      <th>x2_SD</th>\n",
       "      <th>x2_TN</th>\n",
       "      <th>x2_TX</th>\n",
       "      <th>x2_UNKOWN</th>\n",
       "      <th>x2_UT</th>\n",
       "      <th>x2_VA</th>\n",
       "      <th>x2_VT</th>\n",
       "      <th>x2_WA</th>\n",
       "      <th>x2_WI</th>\n",
       "      <th>x2_WV</th>\n",
       "      <th>x2_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>782.833600</td>\n",
       "      <td>366.785559</td>\n",
       "      <td>101.8000</td>\n",
       "      <td>1.645198</td>\n",
       "      <td>4541.958000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>4.615192</td>\n",
       "      <td>9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.313333</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>6.684615</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.213333</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2574.600000</td>\n",
       "      <td>17.734</td>\n",
       "      <td>0.859</td>\n",
       "      <td>11.823566</td>\n",
       "      <td>21.235623</td>\n",
       "      <td>21.50583</td>\n",
       "      <td>34.175679</td>\n",
       "      <td>33.543717</td>\n",
       "      <td>1.524717</td>\n",
       "      <td>16.239151</td>\n",
       "      <td>0.918275</td>\n",
       "      <td>0.056321</td>\n",
       "      <td>0.143981</td>\n",
       "      <td>0.115075</td>\n",
       "      <td>0.338151</td>\n",
       "      <td>0.084509</td>\n",
       "      <td>0.087226</td>\n",
       "      <td>0.168151</td>\n",
       "      <td>0.286868</td>\n",
       "      <td>0.187755</td>\n",
       "      <td>0.305979</td>\n",
       "      <td>0.343623</td>\n",
       "      <td>0.106472</td>\n",
       "      <td>0.343717</td>\n",
       "      <td>0.442604</td>\n",
       "      <td>0.25917</td>\n",
       "      <td>0.446755</td>\n",
       "      <td>0.630755</td>\n",
       "      <td>0.363245</td>\n",
       "      <td>0.412075</td>\n",
       "      <td>0.365377</td>\n",
       "      <td>0.058755</td>\n",
       "      <td>0.051531</td>\n",
       "      <td>0.213057</td>\n",
       "      <td>0.394038</td>\n",
       "      <td>0.30334</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>2.293075</td>\n",
       "      <td>0.122640</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>0.405415</td>\n",
       "      <td>1.03334</td>\n",
       "      <td>0.739472</td>\n",
       "      <td>0.270154</td>\n",
       "      <td>0.612755</td>\n",
       "      <td>7.196717</td>\n",
       "      <td>0.883434</td>\n",
       "      <td>0.546849</td>\n",
       "      <td>0.456189</td>\n",
       "      <td>2.156038</td>\n",
       "      <td>187.848060</td>\n",
       "      <td>290.917100</td>\n",
       "      <td>0.504208</td>\n",
       "      <td>1.285528</td>\n",
       "      <td>2.13234</td>\n",
       "      <td>63.170255</td>\n",
       "      <td>12.725981</td>\n",
       "      <td>1.479057</td>\n",
       "      <td>18.711434</td>\n",
       "      <td>12.762321</td>\n",
       "      <td>2.210755</td>\n",
       "      <td>4.239057</td>\n",
       "      <td>11.17266</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.029585</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.052623</td>\n",
       "      <td>1.372</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>782.833600</td>\n",
       "      <td>366.785559</td>\n",
       "      <td>101.8000</td>\n",
       "      <td>1.645198</td>\n",
       "      <td>4541.958000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>4.615192</td>\n",
       "      <td>9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.313333</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>6.684615</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.213333</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2574.600000</td>\n",
       "      <td>17.734</td>\n",
       "      <td>0.859</td>\n",
       "      <td>11.823566</td>\n",
       "      <td>21.235623</td>\n",
       "      <td>21.50583</td>\n",
       "      <td>34.175679</td>\n",
       "      <td>33.543717</td>\n",
       "      <td>1.524717</td>\n",
       "      <td>16.239151</td>\n",
       "      <td>0.918275</td>\n",
       "      <td>0.056321</td>\n",
       "      <td>0.143981</td>\n",
       "      <td>0.115075</td>\n",
       "      <td>0.338151</td>\n",
       "      <td>0.084509</td>\n",
       "      <td>0.087226</td>\n",
       "      <td>0.168151</td>\n",
       "      <td>0.286868</td>\n",
       "      <td>0.187755</td>\n",
       "      <td>0.305979</td>\n",
       "      <td>0.343623</td>\n",
       "      <td>0.106472</td>\n",
       "      <td>0.343717</td>\n",
       "      <td>0.442604</td>\n",
       "      <td>0.25917</td>\n",
       "      <td>0.446755</td>\n",
       "      <td>0.630755</td>\n",
       "      <td>0.363245</td>\n",
       "      <td>0.412075</td>\n",
       "      <td>0.365377</td>\n",
       "      <td>0.058755</td>\n",
       "      <td>0.051531</td>\n",
       "      <td>0.213057</td>\n",
       "      <td>0.394038</td>\n",
       "      <td>0.30334</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>2.293075</td>\n",
       "      <td>0.122640</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>0.405415</td>\n",
       "      <td>1.03334</td>\n",
       "      <td>0.739472</td>\n",
       "      <td>0.270154</td>\n",
       "      <td>0.612755</td>\n",
       "      <td>7.196717</td>\n",
       "      <td>0.883434</td>\n",
       "      <td>0.546849</td>\n",
       "      <td>0.456189</td>\n",
       "      <td>2.156038</td>\n",
       "      <td>187.848060</td>\n",
       "      <td>290.917100</td>\n",
       "      <td>0.504208</td>\n",
       "      <td>1.285528</td>\n",
       "      <td>2.13234</td>\n",
       "      <td>63.170255</td>\n",
       "      <td>12.725981</td>\n",
       "      <td>1.479057</td>\n",
       "      <td>18.711434</td>\n",
       "      <td>12.762321</td>\n",
       "      <td>2.210755</td>\n",
       "      <td>4.239057</td>\n",
       "      <td>11.17266</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.029585</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.052623</td>\n",
       "      <td>1.372</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>904.028000</td>\n",
       "      <td>298.014814</td>\n",
       "      <td>28.4900</td>\n",
       "      <td>47.697865</td>\n",
       "      <td>8377.516600</td>\n",
       "      <td>0.3</td>\n",
       "      <td>53.800000</td>\n",
       "      <td>4.764452</td>\n",
       "      <td>9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>9.233333</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>6.646667</td>\n",
       "      <td>4.9</td>\n",
       "      <td>7.744444</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.625</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.562500</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2461.777778</td>\n",
       "      <td>21.509</td>\n",
       "      <td>0.659</td>\n",
       "      <td>9.751000</td>\n",
       "      <td>17.687000</td>\n",
       "      <td>17.80800</td>\n",
       "      <td>17.869000</td>\n",
       "      <td>17.869000</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>7.094000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.07600</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>1.624000</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.26700</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.303643</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>2.137000</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>6.552000</td>\n",
       "      <td>8.020000</td>\n",
       "      <td>0.534000</td>\n",
       "      <td>1.208000</td>\n",
       "      <td>1.93700</td>\n",
       "      <td>26.711000</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>2.023000</td>\n",
       "      <td>17.101000</td>\n",
       "      <td>8.836000</td>\n",
       "      <td>3.307000</td>\n",
       "      <td>4.192000</td>\n",
       "      <td>6.58500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>1.539</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>414.530571</td>\n",
       "      <td>217.735313</td>\n",
       "      <td>-18.2404</td>\n",
       "      <td>58.419463</td>\n",
       "      <td>7874.708571</td>\n",
       "      <td>0.2</td>\n",
       "      <td>56.285714</td>\n",
       "      <td>4.680252</td>\n",
       "      <td>11</td>\n",
       "      <td>7.1</td>\n",
       "      <td>11.573333</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>6.108333</td>\n",
       "      <td>6.6</td>\n",
       "      <td>10.153333</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3351.533333</td>\n",
       "      <td>-176.920</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-68.911000</td>\n",
       "      <td>-42.100000</td>\n",
       "      <td>-42.10000</td>\n",
       "      <td>-40.790000</td>\n",
       "      <td>-40.790000</td>\n",
       "      <td>11.652000</td>\n",
       "      <td>-190.730000</td>\n",
       "      <td>3.348355</td>\n",
       "      <td>-0.286000</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.234000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>-0.266000</td>\n",
       "      <td>-0.227000</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>-0.761000</td>\n",
       "      <td>-0.214000</td>\n",
       "      <td>0.212514</td>\n",
       "      <td>-0.866000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.866000</td>\n",
       "      <td>-0.878000</td>\n",
       "      <td>-0.19200</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.055147</td>\n",
       "      <td>0.428000</td>\n",
       "      <td>0.036425</td>\n",
       "      <td>0.14700</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>-4.429000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.478000</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>-0.18100</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>26.342000</td>\n",
       "      <td>2.617000</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>9.655000</td>\n",
       "      <td>142.505205</td>\n",
       "      <td>143.585931</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.11300</td>\n",
       "      <td>65.922574</td>\n",
       "      <td>114.706167</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>6.305000</td>\n",
       "      <td>19.236988</td>\n",
       "      <td>1.129000</td>\n",
       "      <td>4.762000</td>\n",
       "      <td>9.12300</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>65.327</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>367.344000</td>\n",
       "      <td>138.314338</td>\n",
       "      <td>44.5675</td>\n",
       "      <td>86.727219</td>\n",
       "      <td>2974.464600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3.807887</td>\n",
       "      <td>3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>5.537500</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>9.6</td>\n",
       "      <td>10.237500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.375</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>842.250000</td>\n",
       "      <td>242.316</td>\n",
       "      <td>0.825</td>\n",
       "      <td>10.702000</td>\n",
       "      <td>30.686000</td>\n",
       "      <td>30.68600</td>\n",
       "      <td>41.845000</td>\n",
       "      <td>40.614000</td>\n",
       "      <td>1.162000</td>\n",
       "      <td>5.059000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.06700</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.437738</td>\n",
       "      <td>0.083165</td>\n",
       "      <td>1.186000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224102</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.52600</td>\n",
       "      <td>1.198000</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>3.209000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.337000</td>\n",
       "      <td>-81.590565</td>\n",
       "      <td>-50.639946</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>3.391000</td>\n",
       "      <td>4.34900</td>\n",
       "      <td>147.844000</td>\n",
       "      <td>3.417000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>3.742000</td>\n",
       "      <td>6.342000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>1.55700</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>1.363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CEO_FEMALE  EXECDIR_COUNT  AVG_SALARY  STD_SALARY  AVG_SALPCT  STD_SALPCT  \\\n",
       "0           1              2  782.833600  366.785559    101.8000    1.645198   \n",
       "1           1              2  782.833600  366.785559    101.8000    1.645198   \n",
       "2           1              2  904.028000  298.014814     28.4900   47.697865   \n",
       "3           0              2  414.530571  217.735313    -18.2404   58.419463   \n",
       "4           0              2  367.344000  138.314338     44.5675   86.727219   \n",
       "\n",
       "   AVG_TOTAL_COMP  NationalityMix    AVG_AGE   STD_AGE  Length_term  STDEVAge  \\\n",
       "0     4541.958000             0.2  55.600000  4.615192            9       4.5   \n",
       "1     4541.958000             0.2  55.600000  4.615192            9       4.5   \n",
       "2     8377.516600             0.3  53.800000  4.764452            9       4.9   \n",
       "3     7874.708571             0.2  56.285714  4.680252           11       7.1   \n",
       "4     2974.464600             0.0  55.000000  3.807887            3       8.4   \n",
       "\n",
       "   TimeRetirement  TimeRole   TimeBrd  STDEVTimeBrd   TimeInCo  STDEVTimeInCo  \\\n",
       "0        9.313333  4.900000  6.684615           4.3   6.213333            4.3   \n",
       "1        9.313333  4.900000  6.684615           4.3   6.213333            4.3   \n",
       "2        9.233333  4.566667  6.646667           4.9   7.744444            4.6   \n",
       "3       11.573333  4.566667  6.108333           6.6  10.153333            7.9   \n",
       "4        7.125000  5.537500  9.800000           9.6  10.237500           10.0   \n",
       "\n",
       "   TotNoLstdBrd  STDEVTotNoLstdBrd  TotNoUnLstdBrd  TotCurrNoLstdBrd  \\\n",
       "0         3.500                1.0        4.285714          2.307692   \n",
       "1         3.500                1.0        4.285714          2.307692   \n",
       "2         3.625                1.6        4.562500          2.437500   \n",
       "3         5.000                3.4        4.090909          2.500000   \n",
       "4         3.375                1.3        4.000000          1.625000   \n",
       "\n",
       "   TotCurrNoUnLstdBrd   NoQuals  STDEVNoQuals  Succession  NetworkSize  \\\n",
       "0            2.000000  2.200000           1.0         0.2  2574.600000   \n",
       "1            2.000000  2.200000           1.0         0.2  2574.600000   \n",
       "2            2.571429  2.222222           0.9         0.2  2461.777778   \n",
       "3            2.000000  1.933333           0.5         0.4  3351.533333   \n",
       "4            2.000000  1.750000           0.8         0.3   842.250000   \n",
       "\n",
       "     CAPEI     bm        evm  pe_op_basic  pe_op_dil     pe_exi     pe_inc  \\\n",
       "0   17.734  0.859  11.823566    21.235623   21.50583  34.175679  33.543717   \n",
       "1   17.734  0.859  11.823566    21.235623   21.50583  34.175679  33.543717   \n",
       "2   21.509  0.659   9.751000    17.687000   17.80800  17.869000  17.869000   \n",
       "3 -176.920  0.007 -68.911000   -42.100000  -42.10000 -40.790000 -40.790000   \n",
       "4  242.316  0.825  10.702000    30.686000   30.68600  41.845000  40.614000   \n",
       "\n",
       "          ps         pcf       dpr       npm     opmbd     opmad       gpm  \\\n",
       "0   1.524717   16.239151  0.918275  0.056321  0.143981  0.115075  0.338151   \n",
       "1   1.524717   16.239151  0.918275  0.056321  0.143981  0.115075  0.338151   \n",
       "2   0.396000    7.094000  0.310000  0.023000  0.043000  0.033000  0.063000   \n",
       "3  11.652000 -190.730000  3.348355 -0.286000 -0.175000 -0.234000  0.888000   \n",
       "4   1.162000    5.059000  0.000000  0.028000  0.101000  0.063000  0.372000   \n",
       "\n",
       "       ptpm       cfm       roa       roe      roce    efftax  aftret_eq  \\\n",
       "0  0.084509  0.087226  0.168151  0.286868  0.187755  0.305979   0.343623   \n",
       "1  0.084509  0.087226  0.168151  0.286868  0.187755  0.305979   0.343623   \n",
       "2  0.033000  0.033000  0.088000  0.090000  0.106000  0.331000   0.096000   \n",
       "3 -0.266000 -0.227000 -0.075000 -0.761000 -0.214000  0.212514  -0.866000   \n",
       "4  0.048000  0.066000  0.087000  0.031000  0.072000  0.270000   0.032000   \n",
       "\n",
       "   aftret_invcapx  aftret_equity  pretret_noa  pretret_earnat     GProf  \\\n",
       "0        0.106472       0.343717     0.442604         0.25917  0.446755   \n",
       "1        0.106472       0.343717     0.442604         0.25917  0.446755   \n",
       "2        0.085000       0.096000     0.122000         0.07600  0.128000   \n",
       "3        0.000000      -0.866000    -0.878000        -0.19200  0.397000   \n",
       "4        0.000000       0.032000     0.085000         0.06700  0.326000   \n",
       "\n",
       "   equity_invcap  debt_invcap  totdebt_invcap  capital_ratio   int_debt  \\\n",
       "0       0.630755     0.363245        0.412075       0.365377   0.058755   \n",
       "1       0.630755     0.363245        0.412075       0.365377   0.058755   \n",
       "2       0.789000     0.210000        0.232000       0.210000   0.065000   \n",
       "3       0.237000     0.763000        0.877000       0.763000   0.066985   \n",
       "4       1.000000     0.000000        0.000000       0.000000  16.437738   \n",
       "\n",
       "   int_totdebt   cash_lt  invt_act  rect_act   debt_at  debt_ebitda  \\\n",
       "0     0.051531  0.213057  0.394038   0.30334  0.276189     2.293075   \n",
       "1     0.051531  0.213057  0.394038   0.30334  0.276189     2.293075   \n",
       "2     0.058000  0.339000  0.376000   0.18600  0.142000     1.624000   \n",
       "3     0.055147  0.428000  0.036425   0.14700  0.347000    -4.429000   \n",
       "4     0.083165  1.186000  0.220000   0.32000  0.000000     0.000000   \n",
       "\n",
       "   short_debt  curr_debt   lt_debt  profit_lct   ocf_lct  cash_debt   fcf_ocf  \\\n",
       "0    0.122640   0.396038  0.405415     1.03334  0.739472   0.270154  0.612755   \n",
       "1    0.122640   0.396038  0.405415     1.03334  0.739472   0.270154  0.612755   \n",
       "2    0.097000   0.635000  0.248000     0.26700  0.345000   0.303643  0.818000   \n",
       "3    0.130000   0.478000  0.333000    -0.18100 -0.033000   0.042000  0.552000   \n",
       "4    0.224102   0.666000  0.000000     0.52600  1.198000   0.302000  0.895000   \n",
       "\n",
       "    lt_ppent   dltt_be  debt_assets  debt_capital  de_ratio      intcov  \\\n",
       "0   7.196717  0.883434     0.546849      0.456189  2.156038  187.848060   \n",
       "1   7.196717  0.883434     0.546849      0.456189  2.156038  187.848060   \n",
       "2   2.137000  0.247000     0.516000      0.422000  1.070000    6.552000   \n",
       "3  26.342000  2.617000     0.906000      0.797000  9.655000  142.505205   \n",
       "4   3.209000  0.000000     0.252000      0.102000  0.337000  -81.590565   \n",
       "\n",
       "   intcov_ratio  cash_ratio  quick_ratio  curr_ratio  cash_conversion  \\\n",
       "0    290.917100    0.504208     1.285528     2.13234        63.170255   \n",
       "1    290.917100    0.504208     1.285528     2.13234        63.170255   \n",
       "2      8.020000    0.534000     1.208000     1.93700        26.711000   \n",
       "3    143.585931    0.894000     1.058000     1.11300        65.922574   \n",
       "4    -50.639946    1.780000     3.391000     4.34900       147.844000   \n",
       "\n",
       "     inv_turn   at_turn  rect_turn   pay_turn  sale_invcap  sale_equity  \\\n",
       "0   12.725981  1.479057  18.711434  12.762321     2.210755     4.239057   \n",
       "1   12.725981  1.479057  18.711434  12.762321     2.210755     4.239057   \n",
       "2    7.930000  2.023000  17.101000   8.836000     3.307000     4.192000   \n",
       "3  114.706167  0.447000   6.305000  19.236988     1.129000     4.762000   \n",
       "4    3.417000  0.875000   3.742000   6.342000     1.170000     1.170000   \n",
       "\n",
       "   sale_nwc   rd_sale  adv_sale  staff_sale   accrual     ptb  FEMALE_PCT  \\\n",
       "0  11.17266  0.006698  0.029585    0.002019  0.052623   1.372    0.200000   \n",
       "1  11.17266  0.006698  0.029585    0.002019  0.052623   1.372    0.200000   \n",
       "2   6.58500  0.001000  0.000000    0.000000  0.067000   1.539    0.200000   \n",
       "3   9.12300  0.384000  0.017000    0.000000  0.112000  65.327    0.142857   \n",
       "4   1.55700  0.130000  0.000000    0.000000  0.174000   1.363    0.000000   \n",
       "\n",
       "   FEMALE_PCT_LAST  x0_2012  x0_2013  x0_2014  x0_2015  x0_2016  x0_2017  \\\n",
       "0         0.142857        0        1        0        0        0        0   \n",
       "1         0.142857        0        1        0        0        0        0   \n",
       "2         0.200000        0        0        1        0        0        0   \n",
       "3         0.000000        0        0        0        0        0        1   \n",
       "4         0.000000        1        0        0        0        0        0   \n",
       "\n",
       "   x0_2018  x0_2019  x0_2020  x1_Automobiles & Parts  x1_Banks  x1_Beverages  \\\n",
       "0        0        0        0                       0         0             0   \n",
       "1        0        0        0                       0         0             0   \n",
       "2        0        0        0                       0         0             0   \n",
       "3        0        0        0                       0         0             0   \n",
       "4        0        0        0                       0         0             0   \n",
       "\n",
       "   x1_Business Services  x1_Chemicals  x1_Clothing & Personal Products  \\\n",
       "0                     0             0                                0   \n",
       "1                     0             0                                0   \n",
       "2                     0             0                                0   \n",
       "3                     0             0                                0   \n",
       "4                     0             0                                0   \n",
       "\n",
       "   x1_Construction & Building Materials  x1_Consumer Services  \\\n",
       "0                                     0                     0   \n",
       "1                                     0                     0   \n",
       "2                                     0                     0   \n",
       "3                                     0                     0   \n",
       "4                                     0                     0   \n",
       "\n",
       "   x1_Containers & Packaging  x1_Diversified Industrials  x1_Education  \\\n",
       "0                          0                           0             0   \n",
       "1                          0                           0             0   \n",
       "2                          0                           0             0   \n",
       "3                          0                           0             0   \n",
       "4                          0                           0             0   \n",
       "\n",
       "   x1_Electricity  x1_Electronic & Electrical Equipment  \\\n",
       "0               0                                     0   \n",
       "1               0                                     0   \n",
       "2               0                                     0   \n",
       "3               0                                     0   \n",
       "4               0                                     1   \n",
       "\n",
       "   x1_Engineering & Machinery  x1_Food & Drug Retailers  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "\n",
       "   x1_Food Producers & Processors  x1_Forestry & Paper  x1_General Retailers  \\\n",
       "0                               1                    0                     0   \n",
       "1                               1                    0                     0   \n",
       "2                               1                    0                     0   \n",
       "3                               0                    0                     0   \n",
       "4                               0                    0                     0   \n",
       "\n",
       "   x1_Health  x1_Household Products  x1_Information Technology Hardware  \\\n",
       "0          0                      0                                   0   \n",
       "1          0                      0                                   0   \n",
       "2          0                      0                                   0   \n",
       "3          0                      0                                   0   \n",
       "4          0                      0                                   0   \n",
       "\n",
       "   x1_Insurance  x1_Leisure & Hotels  x1_Leisure Goods  \\\n",
       "0             0                    0                 0   \n",
       "1             0                    0                 0   \n",
       "2             0                    0                 0   \n",
       "3             0                    0                 0   \n",
       "4             0                    0                 0   \n",
       "\n",
       "   x1_Media & Entertainment  x1_Mining  x1_Oil & Gas  \\\n",
       "0                         0          0             0   \n",
       "1                         0          0             0   \n",
       "2                         0          0             0   \n",
       "3                         0          0             0   \n",
       "4                         0          0             0   \n",
       "\n",
       "   x1_Pharmaceuticals and Biotechnology  x1_Publishing  x1_Real Estate  \\\n",
       "0                                     0              0               0   \n",
       "1                                     0              0               0   \n",
       "2                                     0              0               0   \n",
       "3                                     0              0               0   \n",
       "4                                     0              0               0   \n",
       "\n",
       "   x1_Renewable Energy  x1_Software & Computer Services  \\\n",
       "0                    0                                0   \n",
       "1                    0                                0   \n",
       "2                    0                                0   \n",
       "3                    0                                1   \n",
       "4                    0                                0   \n",
       "\n",
       "   x1_Speciality & Other Finance  x1_Steel & Other Metals  \\\n",
       "0                              0                        0   \n",
       "1                              0                        0   \n",
       "2                              0                        0   \n",
       "3                              0                        0   \n",
       "4                              0                        0   \n",
       "\n",
       "   x1_Telecommunication Services  x1_Tobacco  x1_Transport  \\\n",
       "0                              0           0             0   \n",
       "1                              0           0             0   \n",
       "2                              0           0             0   \n",
       "3                              0           0             0   \n",
       "4                              0           0             0   \n",
       "\n",
       "   x1_Utilities - Other  x1_other_sector  x2_AR  x2_AZ  x2_BC  x2_CA  x2_CO  \\\n",
       "0                     0                0      0      0      0      0      0   \n",
       "1                     0                0      0      0      0      0      0   \n",
       "2                     0                0      0      0      0      0      0   \n",
       "3                     0                0      0      0      0      1      0   \n",
       "4                     0                0      0      0      0      0      1   \n",
       "\n",
       "   x2_CT  x2_DC  x2_DE  x2_FL  x2_GA  x2_HI  x2_IA  x2_ID  x2_IL  x2_IN  \\\n",
       "0      0      0      0      0      0      0      0      0      1      0   \n",
       "1      0      0      0      0      0      0      0      0      1      0   \n",
       "2      0      0      0      0      0      0      0      0      1      0   \n",
       "3      0      0      0      0      0      0      0      0      0      0   \n",
       "4      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   x2_KS  x2_KY  x2_LA  x2_MA  x2_MD  x2_ME  x2_MI  x2_MN  x2_MO  x2_MS  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0   \n",
       "1      0      0      0      0      0      0      0      0      0      0   \n",
       "2      0      0      0      0      0      0      0      0      0      0   \n",
       "3      0      0      0      0      0      0      0      0      0      0   \n",
       "4      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   x2_MT  x2_NC  x2_ND  x2_NE  x2_NH  x2_NJ  x2_NM  x2_NV  x2_NY  x2_OH  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0   \n",
       "1      0      0      0      0      0      0      0      0      0      0   \n",
       "2      0      0      0      0      0      0      0      0      0      0   \n",
       "3      0      0      0      0      0      0      0      0      0      0   \n",
       "4      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   x2_OK  x2_ON  x2_OR  x2_PA  x2_PR  x2_QC  x2_RI  x2_SC  x2_SD  x2_TN  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0   \n",
       "1      0      0      0      0      0      0      0      0      0      0   \n",
       "2      0      0      0      0      0      0      0      0      0      0   \n",
       "3      0      0      0      0      0      0      0      0      0      0   \n",
       "4      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   x2_TX  x2_UNKOWN  x2_UT  x2_VA  x2_VT  x2_WA  x2_WI  x2_WV  x2_WY  \n",
       "0      0          0      0      0      0      0      0      0      0  \n",
       "1      0          0      0      0      0      0      0      0      0  \n",
       "2      0          0      0      0      0      0      0      0      0  \n",
       "3      0          0      0      0      0      0      0      0      0  \n",
       "4      0          0      0      0      0      0      0      0      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FEMALE_PCT_LAST                         0.842876\n",
       "CEO_FEMALE                              0.341347\n",
       "x1_General Retailers                    0.123554\n",
       "NetworkSize                             0.083740\n",
       "GProf                                   0.076943\n",
       "x1_Utilities - Other                    0.071347\n",
       "x0_2019                                 0.067328\n",
       "x2_MN                                   0.058776\n",
       "at_turn                                 0.050807\n",
       "adv_sale                                0.050115\n",
       "x2_HI                                   0.048646\n",
       "x0_2018                                 0.044680\n",
       "TimeRetirement                          0.044423\n",
       "x1_other_sector                         0.044057\n",
       "x2_NJ                                   0.041579\n",
       "x1_Electricity                          0.040353\n",
       "x1_Business Services                    0.040326\n",
       "x2_WA                                   0.040199\n",
       "x0_2020                                 0.039502\n",
       "x2_ME                                   0.039374\n",
       "x2_OH                                   0.038126\n",
       "roa                                     0.036142\n",
       "x1_Health                               0.035577\n",
       "x2_CA                                   0.034500\n",
       "x1_Education                            0.032738\n",
       "x2_IN                                   0.032658\n",
       "x1_Publishing                           0.031645\n",
       "x2_AZ                                   0.028972\n",
       "x0_2017                                 0.027962\n",
       "aftret_invcapx                          0.027587\n",
       "x2_SD                                   0.026796\n",
       "x1_Consumer Services                    0.025787\n",
       "STD_SALARY                              0.023757\n",
       "invt_act                                0.023630\n",
       "x2_VA                                   0.022777\n",
       "roe                                     0.022336\n",
       "ptb                                     0.021966\n",
       "x2_NM                                   0.021832\n",
       "NoQuals                                 0.021803\n",
       "pretret_earnat                          0.021696\n",
       "x1_Media & Entertainment                0.021297\n",
       "x2_RI                                   0.021215\n",
       "x1_Leisure & Hotels                     0.020706\n",
       "TotNoLstdBrd                            0.020208\n",
       "AVG_SALARY                              0.018902\n",
       "x1_Food & Drug Retailers                0.017023\n",
       "rect_turn                               0.016364\n",
       "sale_invcap                             0.016290\n",
       "dpr                                     0.015245\n",
       "x1_Clothing & Personal Products         0.015014\n",
       "TotCurrNoLstdBrd                        0.014345\n",
       "STD_SALPCT                              0.014313\n",
       "x2_VT                                   0.013738\n",
       "x2_IA                                   0.013326\n",
       "int_totdebt                             0.013270\n",
       "x2_NH                                   0.013114\n",
       "debt_assets                             0.012446\n",
       "cash_conversion                         0.011999\n",
       "roce                                    0.011738\n",
       "debt_ebitda                             0.011313\n",
       "x2_QC                                   0.010952\n",
       "x2_LA                                   0.009828\n",
       "x2_DE                                   0.009577\n",
       "x2_NE                                   0.009556\n",
       "x1_Household Products                   0.009214\n",
       "x0_2016                                 0.009038\n",
       "x1_Chemicals                            0.008893\n",
       "x2_MD                                   0.008683\n",
       "AVG_SALPCT                              0.008557\n",
       "intcov_ratio                            0.008289\n",
       "STDEVTotNoLstdBrd                       0.008185\n",
       "debt_capital                            0.008075\n",
       "pe_exi                                  0.007499\n",
       "pcf                                     0.007114\n",
       "de_ratio                                0.007018\n",
       "pay_turn                                0.006825\n",
       "CAPEI                                   0.006680\n",
       "sale_equity                             0.006450\n",
       "debt_invcap                             0.006370\n",
       "x1_Forestry & Paper                     0.006294\n",
       "pe_inc                                  0.006206\n",
       "pretret_noa                             0.005576\n",
       "accrual                                 0.005572\n",
       "curr_debt                               0.005362\n",
       "intcov                                  0.005207\n",
       "totdebt_invcap                          0.005135\n",
       "x2_KY                                   0.004711\n",
       "profit_lct                              0.003980\n",
       "ocf_lct                                 0.003800\n",
       "x2_PR                                   0.003605\n",
       "Succession                              0.003377\n",
       "efftax                                  0.002612\n",
       "cfm                                     0.002501\n",
       "x2_TN                                   0.002273\n",
       "gpm                                     0.002273\n",
       "sale_nwc                                0.002242\n",
       "x1_Mining                               0.002175\n",
       "pe_op_dil                               0.002079\n",
       "capital_ratio                           0.002052\n",
       "opmad                                   0.001997\n",
       "cash_debt                               0.001946\n",
       "npm                                     0.001892\n",
       "pe_op_basic                             0.001868\n",
       "ptpm                                    0.001794\n",
       "fcf_ocf                                 0.001748\n",
       "opmbd                                   0.001592\n",
       "x2_FL                                   0.000955\n",
       "x1_Real Estate                          0.000120\n",
       "x2_NY                                  -0.000271\n",
       "x2_WV                                  -0.000785\n",
       "lt_ppent                               -0.000825\n",
       "AVG_TOTAL_COMP                         -0.000846\n",
       "x1_Banks                               -0.001074\n",
       "x2_OR                                  -0.001338\n",
       "dltt_be                                -0.001388\n",
       "x1_Pharmaceuticals and Biotechnology   -0.001702\n",
       "aftret_equity                          -0.001944\n",
       "x1_Diversified Industrials             -0.002277\n",
       "x2_MO                                  -0.002623\n",
       "aftret_eq                              -0.002856\n",
       "equity_invcap                          -0.003638\n",
       "x1_Information Technology Hardware     -0.004236\n",
       "cash_lt                                -0.004499\n",
       "short_debt                             -0.005558\n",
       "int_debt                               -0.005818\n",
       "x2_CO                                  -0.005841\n",
       "x2_AR                                  -0.005879\n",
       "x2_ND                                  -0.005963\n",
       "x2_UNKOWN                              -0.007062\n",
       "NationalityMix                         -0.008335\n",
       "x1_Leisure Goods                       -0.008352\n",
       "STDEVNoQuals                           -0.009038\n",
       "x1_Food Producers & Processors         -0.009920\n",
       "bm                                     -0.009992\n",
       "rd_sale                                -0.010562\n",
       "cash_ratio                             -0.011007\n",
       "TotNoUnLstdBrd                         -0.011290\n",
       "x1_Renewable Energy                    -0.012191\n",
       "staff_sale                             -0.012297\n",
       "x2_NC                                  -0.012446\n",
       "debt_at                                -0.013179\n",
       "x2_IL                                  -0.013852\n",
       "x2_ID                                  -0.014031\n",
       "x2_DC                                  -0.014115\n",
       "x0_2015                                -0.014238\n",
       "inv_turn                               -0.014487\n",
       "x2_WY                                  -0.014949\n",
       "x1_Engineering & Machinery             -0.015526\n",
       "x1_Insurance                           -0.015771\n",
       "ps                                     -0.016148\n",
       "x1_Speciality & Other Finance          -0.016328\n",
       "x2_PA                                  -0.016577\n",
       "x2_CT                                  -0.016891\n",
       "x2_MT                                  -0.016951\n",
       "x2_BC                                  -0.016951\n",
       "x2_OK                                  -0.016994\n",
       "quick_ratio                            -0.017346\n",
       "x1_Tobacco                             -0.017440\n",
       "x1_Beverages                           -0.017936\n",
       "curr_ratio                             -0.018440\n",
       "x1_Software & Computer Services        -0.018474\n",
       "x2_KS                                  -0.018911\n",
       "x2_SC                                  -0.019072\n",
       "x1_Transport                           -0.021253\n",
       "x1_Containers & Packaging              -0.022568\n",
       "x2_ON                                  -0.024089\n",
       "evm                                    -0.025140\n",
       "Length_term                            -0.026050\n",
       "x2_TX                                  -0.026898\n",
       "x1_Telecommunication Services          -0.027426\n",
       "x1_Steel & Other Metals                -0.028029\n",
       "TotCurrNoUnLstdBrd                     -0.028341\n",
       "x2_NV                                  -0.030909\n",
       "x0_2014                                -0.031056\n",
       "rect_act                               -0.032667\n",
       "x2_MI                                  -0.033217\n",
       "x2_WI                                  -0.033455\n",
       "x0_2012                                -0.033903\n",
       "x0_2013                                -0.035331\n",
       "x1_Automobiles & Parts                 -0.038261\n",
       "x2_MS                                  -0.038287\n",
       "lt_debt                                -0.038883\n",
       "x2_GA                                  -0.040232\n",
       "x2_UT                                  -0.040937\n",
       "STDEVAge                               -0.042984\n",
       "STDEVTimeInCo                          -0.047877\n",
       "STD_AGE                                -0.049150\n",
       "x1_Oil & Gas                           -0.052562\n",
       "x2_MA                                  -0.055319\n",
       "x1_Construction & Building Materials   -0.058194\n",
       "AVG_AGE                                -0.062077\n",
       "STDEVTimeBrd                           -0.063136\n",
       "TimeRole                               -0.065626\n",
       "EXECDIR_COUNT                          -0.068386\n",
       "TimeInCo                               -0.072541\n",
       "x1_Electronic & Electrical Equipment   -0.072866\n",
       "TimeBrd                                -0.080938\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute correlation between numeric features and target variables\n",
    "num_data.drop(\"FEMALE_PCT\", axis=1).apply(lambda x: x.corr(num_data.FEMALE_PCT)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to this link below for different sklearn regressor packages:\n",
    "https://urldefense.com/v3/__https://scikit-learn.org/stable/modules/classes.html*module-sklearn.linear_model__;Iw!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_Yg0lQlCo$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In linear regression model, the model makes the following assumptions for the data we provide, such as:\n",
    "1) Linearity: assumes that the relationship between predictors and target variable is linear\n",
    "\n",
    "2) No noise: eg. that there are no outliers in the data\n",
    "\n",
    "3) No collinearity: if you have highly correlated predictors, it’s most likely your model will overfit\n",
    "\n",
    "4) Normal distribution: more reliable predictions are made if the predictors and the target variable are normally distributed\n",
    "\n",
    "5) Scale: it’s a distance-based algorithm, so preditors should be scaled — like with standard scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorials can be found at: https://urldefense.com/v3/__https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922__;!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_Y9s6uGwo$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             FEMALE_PCT   R-squared:                       0.722\n",
      "Model:                            OLS   Adj. R-squared:                  0.719\n",
      "Method:                 Least Squares   F-statistic:                     218.2\n",
      "Date:                Sun, 11 Apr 2021   Prob (F-statistic):               0.00\n",
      "Time:                        22:06:31   Log-Likelihood:                 20729.\n",
      "No. Observations:               16725   AIC:                        -4.106e+04\n",
      "Df Residuals:                   16527   BIC:                        -3.953e+04\n",
      "Df Model:                         197                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================================\n",
      "                                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "const                                    0.0512      0.017      2.969      0.003       0.017       0.085\n",
      "AVG_AGE                                 -0.0007      0.000     -3.906      0.000      -0.001      -0.000\n",
      "AVG_SALARY                           -1.054e-05    3.9e-06     -2.705      0.007   -1.82e-05    -2.9e-06\n",
      "AVG_SALPCT                           -3.502e-05   1.85e-05     -1.889      0.059   -7.14e-05    1.33e-06\n",
      "AVG_TOTAL_COMP                       -7.029e-08   9.95e-08     -0.707      0.480   -2.65e-07    1.25e-07\n",
      "CAPEI                                -1.236e-07   1.44e-07     -0.861      0.389   -4.05e-07    1.58e-07\n",
      "CEO_FEMALE                               0.0427      0.003     14.708      0.000       0.037       0.048\n",
      "EXECDIR_COUNT                           -0.0012      0.001     -1.515      0.130      -0.003       0.000\n",
      "FEMALE_PCT_LAST                          0.8151      0.005    174.009      0.000       0.806       0.824\n",
      "GProf                                   -0.0004      0.004     -0.114      0.909      -0.008       0.007\n",
      "Length_term                          -3.031e-06   2.45e-06     -1.236      0.217   -7.84e-06    1.78e-06\n",
      "NationalityMix                           0.0028      0.003      0.825      0.409      -0.004       0.010\n",
      "NetworkSize                           3.199e-06   7.69e-07      4.158      0.000    1.69e-06    4.71e-06\n",
      "NoQuals                                  0.0004      0.001      0.286      0.775      -0.002       0.003\n",
      "STDEVAge                              7.896e-05      0.000      0.179      0.858      -0.001       0.001\n",
      "STDEVNoQuals                            -0.0002      0.002     -0.106      0.915      -0.003       0.003\n",
      "STDEVTimeBrd                            -0.0004      0.001     -0.717      0.474      -0.002       0.001\n",
      "STDEVTimeInCo                            0.0012      0.001      2.142      0.032    9.96e-05       0.002\n",
      "STDEVTotNoLstdBrd                       -0.0014      0.001     -2.127      0.033      -0.003      -0.000\n",
      "STD_AGE                              -8.993e-05      0.000     -0.405      0.686      -0.001       0.000\n",
      "STD_SALARY                            1.436e-05   4.68e-06      3.068      0.002    5.18e-06    2.35e-05\n",
      "STD_SALPCT                            1.531e-05   9.92e-06      1.544      0.123   -4.13e-06    3.48e-05\n",
      "Succession                              -0.0044      0.010     -0.429      0.668      -0.025       0.016\n",
      "TimeBrd                                 -0.0006      0.001     -0.940      0.347      -0.002       0.001\n",
      "TimeInCo                                -0.0002      0.000     -0.397      0.691      -0.001       0.001\n",
      "TimeRetirement                       -8.591e-06      0.000     -0.029      0.977      -0.001       0.001\n",
      "TimeRole                                -0.0001      0.000     -0.260      0.795      -0.001       0.001\n",
      "TotCurrNoLstdBrd                     -5.173e-06      0.002     -0.003      0.998      -0.004       0.003\n",
      "TotCurrNoUnLstdBrd                      -0.0011      0.001     -1.566      0.117      -0.002       0.000\n",
      "TotNoLstdBrd                             0.0009      0.001      0.903      0.367      -0.001       0.003\n",
      "TotNoUnLstdBrd                           0.0002      0.000      0.533      0.594      -0.001       0.001\n",
      "accrual                                 -0.0014      0.009     -0.161      0.872      -0.019       0.016\n",
      "adv_sale                                 0.0283      0.013      2.224      0.026       0.003       0.053\n",
      "aftret_eq                               -0.0042      0.002     -2.381      0.017      -0.008      -0.001\n",
      "aftret_equity                            0.0041      0.002      2.333      0.020       0.001       0.008\n",
      "aftret_invcapx                           0.0030      0.002      1.627      0.104      -0.001       0.007\n",
      "at_turn                                  0.0009      0.001      0.660      0.509      -0.002       0.004\n",
      "bm                                       0.0007      0.001      0.519      0.604      -0.002       0.003\n",
      "capital_ratio                           -0.0016      0.002     -0.970      0.332      -0.005       0.002\n",
      "cash_conversion                       5.845e-09   2.79e-09      2.097      0.036    3.81e-10    1.13e-08\n",
      "cash_debt                               -0.0040      0.002     -2.123      0.034      -0.008      -0.000\n",
      "cash_lt                                 -0.0003      0.001     -0.258      0.796      -0.002       0.002\n",
      "cash_ratio                              -0.0004      0.002     -0.221      0.825      -0.004       0.003\n",
      "cfm                                     -0.0024      0.002     -1.199      0.230      -0.006       0.002\n",
      "curr_debt                                0.0007      0.006      0.130      0.897      -0.010       0.012\n",
      "curr_ratio                              -0.0013      0.002     -0.712      0.477      -0.005       0.002\n",
      "de_ratio                             -3.258e-06    6.6e-06     -0.493      0.622   -1.62e-05    9.69e-06\n",
      "debt_assets                             -0.0063      0.006     -1.109      0.268      -0.017       0.005\n",
      "debt_at                                  0.0012      0.008      0.150      0.881      -0.015       0.017\n",
      "debt_capital                             0.0002      0.000      0.732      0.464      -0.000       0.001\n",
      "debt_ebitda                           6.285e-05   3.31e-05      1.901      0.057   -1.96e-06       0.000\n",
      "debt_invcap                             -0.0011      0.008     -0.133      0.894      -0.017       0.015\n",
      "dltt_be                              -1.428e-05   2.14e-05     -0.669      0.504   -5.61e-05    2.76e-05\n",
      "dpr                                    1.76e-05   9.71e-05      0.181      0.856      -0.000       0.000\n",
      "efftax                                 7.91e-05      0.000      0.387      0.699      -0.000       0.000\n",
      "equity_invcap                            0.0019      0.007      0.251      0.802      -0.013       0.016\n",
      "evm                                  -6.474e-06   2.93e-06     -2.210      0.027   -1.22e-05   -7.33e-07\n",
      "fcf_ocf                                 -0.0003      0.000     -1.350      0.177      -0.001       0.000\n",
      "gpm                                   -6.27e-05      0.001     -0.078      0.938      -0.002       0.002\n",
      "int_debt                             -1.022e-05   3.29e-05     -0.311      0.756   -7.46e-05    5.42e-05\n",
      "int_totdebt                              0.0003      0.000      0.680      0.496      -0.001       0.001\n",
      "intcov                               -1.204e-06   1.32e-06     -0.914      0.361   -3.79e-06    1.38e-06\n",
      "intcov_ratio                            1.9e-06      1e-06      1.896      0.058   -6.47e-08    3.86e-06\n",
      "inv_turn                             -9.357e-08   2.14e-07     -0.436      0.663   -5.14e-07    3.27e-07\n",
      "invt_act                                 0.0054      0.006      0.936      0.349      -0.006       0.017\n",
      "lt_debt                                 -0.0002      0.007     -0.030      0.976      -0.013       0.013\n",
      "lt_ppent                             -5.553e-06   2.09e-06     -2.661      0.008   -9.64e-06   -1.46e-06\n",
      "npm                                      0.0100      0.007      1.375      0.169      -0.004       0.024\n",
      "ocf_lct                                  0.0016      0.002      0.874      0.382      -0.002       0.005\n",
      "opmad                                    0.0008      0.008      0.102      0.919      -0.015       0.017\n",
      "opmbd                                   -0.0002      0.008     -0.025      0.980      -0.017       0.016\n",
      "pay_turn                               7.68e-07   1.93e-06      0.398      0.691   -3.02e-06    4.55e-06\n",
      "pcf                                   2.135e-05   2.14e-05      1.000      0.318   -2.05e-05    6.32e-05\n",
      "pe_exi                                7.736e-06   1.19e-05      0.649      0.517   -1.56e-05    3.11e-05\n",
      "pe_inc                               -2.229e-05    1.3e-05     -1.713      0.087   -4.78e-05    3.22e-06\n",
      "pe_op_basic                          -1.652e-05   3.53e-05     -0.468      0.640   -8.57e-05    5.27e-05\n",
      "pe_op_dil                             1.914e-05   3.53e-05      0.542      0.588   -5.01e-05    8.84e-05\n",
      "pretret_earnat                           0.0111      0.006      2.000      0.046       0.000       0.022\n",
      "pretret_noa                           4.121e-05   6.64e-05      0.621      0.535   -8.89e-05       0.000\n",
      "profit_lct                               0.0001      0.002      0.077      0.939      -0.003       0.004\n",
      "ps                                      -0.0001   9.82e-05     -1.501      0.133      -0.000    4.51e-05\n",
      "ptb                                   4.653e-05      0.000      0.375      0.708      -0.000       0.000\n",
      "ptpm                                    -0.0086      0.007     -1.280      0.201      -0.022       0.005\n",
      "quick_ratio                              0.0028      0.003      0.907      0.364      -0.003       0.009\n",
      "rd_sale                                  0.0010      0.001      1.264      0.206      -0.001       0.002\n",
      "rect_act                                 0.0024      0.005      0.477      0.633      -0.007       0.012\n",
      "rect_turn                            -3.769e-06   3.36e-06     -1.122      0.262   -1.04e-05    2.82e-06\n",
      "roa                                      0.0033      0.011      0.296      0.767      -0.019       0.025\n",
      "roce                                    -0.0004      0.001     -0.293      0.770      -0.003       0.002\n",
      "roe                                     -0.0003      0.001     -0.427      0.670      -0.002       0.001\n",
      "sale_equity                           4.371e-06   6.97e-06      0.627      0.531   -9.29e-06     1.8e-05\n",
      "sale_invcap                             -0.0002      0.000     -0.737      0.461      -0.001       0.000\n",
      "sale_nwc                             -1.432e-06   1.06e-06     -1.350      0.177   -3.51e-06    6.48e-07\n",
      "short_debt                              -0.0002      0.001     -0.255      0.799      -0.002       0.001\n",
      "staff_sale                              -0.0039      0.002     -1.790      0.073      -0.008       0.000\n",
      "totdebt_invcap                           0.0020      0.002      0.834      0.405      -0.003       0.007\n",
      "x0_2012                                  0.0055      0.002      2.417      0.016       0.001       0.010\n",
      "x0_2013                                  0.0020      0.002      0.869      0.385      -0.003       0.007\n",
      "x0_2014                                  0.0054      0.002      2.278      0.023       0.001       0.010\n",
      "x0_2015                                  0.0087      0.002      3.688      0.000       0.004       0.013\n",
      "x0_2016                                  0.0106      0.002      4.429      0.000       0.006       0.015\n",
      "x0_2017                                  0.0114      0.002      4.748      0.000       0.007       0.016\n",
      "x0_2018                                  0.0130      0.002      5.231      0.000       0.008       0.018\n",
      "x0_2019                                  0.0173      0.002      6.996      0.000       0.012       0.022\n",
      "x0_2020                                  0.0291      0.006      4.960      0.000       0.018       0.041\n",
      "x1_Automobiles & Parts                  -0.0100      0.007     -1.443      0.149      -0.024       0.004\n",
      "x1_Banks                                 0.0006      0.007      0.092      0.927      -0.012       0.014\n",
      "x1_Beverages                            -0.0042      0.010     -0.439      0.661      -0.023       0.014\n",
      "x1_Business Services                     0.0033      0.006      0.514      0.607      -0.009       0.016\n",
      "x1_Chemicals                          8.979e-05      0.007      0.014      0.989      -0.013       0.013\n",
      "x1_Clothing & Personal Products          0.0061      0.007      0.846      0.398      -0.008       0.020\n",
      "x1_Construction & Building Materials    -0.0100      0.006     -1.556      0.120      -0.023       0.003\n",
      "x1_Consumer Services                     0.0090      0.008      1.079      0.281      -0.007       0.025\n",
      "x1_Containers & Packaging                0.0030      0.009      0.333      0.739      -0.015       0.020\n",
      "x1_Diversified Industrials              -0.0020      0.009     -0.211      0.833      -0.020       0.016\n",
      "x1_Education                             0.0057      0.010      0.597      0.550      -0.013       0.024\n",
      "x1_Electricity                           0.0055      0.009      0.596      0.551      -0.013       0.024\n",
      "x1_Electronic & Electrical Equipment    -0.0065      0.006     -1.088      0.276      -0.018       0.005\n",
      "x1_Engineering & Machinery              -0.0029      0.006     -0.471      0.638      -0.015       0.009\n",
      "x1_Food & Drug Retailers                 0.0055      0.009      0.628      0.530      -0.012       0.023\n",
      "x1_Food Producers & Processors          -0.0057      0.007     -0.860      0.390      -0.019       0.007\n",
      "x1_Forestry & Paper                     -0.0020      0.008     -0.253      0.800      -0.017       0.013\n",
      "x1_General Retailers                     0.0078      0.006      1.205      0.228      -0.005       0.021\n",
      "x1_Health                                0.0005      0.006      0.085      0.932      -0.012       0.013\n",
      "x1_Household Products                   -0.0011      0.007     -0.149      0.882      -0.015       0.013\n",
      "x1_Information Technology Hardware      -0.0061      0.007     -0.896      0.370      -0.020       0.007\n",
      "x1_Insurance                             0.0032      0.007      0.472      0.637      -0.010       0.017\n",
      "x1_Leisure & Hotels                      0.0007      0.007      0.111      0.912      -0.012       0.014\n",
      "x1_Leisure Goods                        -0.0008      0.010     -0.081      0.936      -0.021       0.020\n",
      "x1_Media & Entertainment                 0.0053      0.007      0.743      0.457      -0.009       0.019\n",
      "x1_Mining                                0.0017      0.007      0.250      0.803      -0.012       0.015\n",
      "x1_Oil & Gas                            -0.0078      0.006     -1.212      0.226      -0.020       0.005\n",
      "x1_Pharmaceuticals and Biotechnology    -0.0011      0.006     -0.170      0.865      -0.014       0.011\n",
      "x1_Publishing                            0.0119      0.008      1.505      0.132      -0.004       0.027\n",
      "x1_Real Estate                           0.0034      0.008      0.432      0.666      -0.012       0.019\n",
      "x1_Renewable Energy                     -0.0064      0.011     -0.604      0.546      -0.027       0.014\n",
      "x1_Software & Computer Services         -0.0039      0.006     -0.625      0.532      -0.016       0.008\n",
      "x1_Speciality & Other Finance           -0.0024      0.006     -0.364      0.716      -0.015       0.010\n",
      "x1_Steel & Other Metals                 -0.0079      0.007     -1.054      0.292      -0.023       0.007\n",
      "x1_Telecommunication Services           -0.0104      0.007     -1.486      0.137      -0.024       0.003\n",
      "x1_Tobacco                              -0.0185      0.012     -1.523      0.128      -0.042       0.005\n",
      "x1_Transport                            -0.0049      0.007     -0.747      0.455      -0.018       0.008\n",
      "x1_Utilities - Other                     0.0159      0.007      2.367      0.018       0.003       0.029\n",
      "x1_other_sector                          0.0193      0.011      1.712      0.087      -0.003       0.041\n",
      "x2_AR                                   -0.0026      0.010     -0.266      0.791      -0.022       0.017\n",
      "x2_AZ                                   -0.0073      0.008     -0.871      0.384      -0.024       0.009\n",
      "x2_BC                                   -0.0200      0.025     -0.793      0.428      -0.070       0.029\n",
      "x2_CA                                   -0.0035      0.007     -0.477      0.633      -0.018       0.011\n",
      "x2_CO                                    0.0023      0.008      0.281      0.779      -0.014       0.018\n",
      "x2_CT                                   -0.0048      0.008     -0.608      0.543      -0.020       0.011\n",
      "x2_DC                                   -0.0066      0.012     -0.566      0.571      -0.029       0.016\n",
      "x2_DE                                    0.0034      0.012      0.276      0.782      -0.021       0.028\n",
      "x2_FL                                   -0.0016      0.008     -0.212      0.832      -0.016       0.013\n",
      "x2_GA                                   -0.0084      0.008     -1.102      0.271      -0.023       0.007\n",
      "x2_HI                                    0.0047      0.011      0.434      0.664      -0.017       0.026\n",
      "x2_IA                                   -0.0007      0.010     -0.065      0.948      -0.020       0.019\n",
      "x2_ID                                   -0.0181      0.012     -1.483      0.138      -0.042       0.006\n",
      "x2_IL                                   -0.0068      0.007     -0.916      0.359      -0.021       0.008\n",
      "x2_IN                                    0.0064      0.008      0.752      0.452      -0.010       0.023\n",
      "x2_KS                                   -0.0031      0.010     -0.309      0.757      -0.023       0.017\n",
      "x2_KY                                   -0.0064      0.010     -0.642      0.521      -0.026       0.013\n",
      "x2_LA                                    0.0064      0.010      0.626      0.531      -0.014       0.026\n",
      "x2_MA                                   -0.0097      0.007     -1.293      0.196      -0.024       0.005\n",
      "x2_MD                                   -0.0024      0.008     -0.296      0.767      -0.019       0.014\n",
      "x2_ME                                    0.0002      0.018      0.013      0.990      -0.036       0.036\n",
      "x2_MI                                   -0.0060      0.008     -0.743      0.457      -0.022       0.010\n",
      "x2_MN                                    0.0026      0.008      0.331      0.741      -0.013       0.018\n",
      "x2_MO                                   -0.0029      0.008     -0.357      0.721      -0.019       0.013\n",
      "x2_MS                                   -0.0167      0.012     -1.396      0.163      -0.040       0.007\n",
      "x2_MT                                   -0.0202      0.025     -0.821      0.412      -0.069       0.028\n",
      "x2_NC                                   -0.0034      0.008     -0.433      0.665      -0.019       0.012\n",
      "x2_ND                                   -0.0107      0.025     -0.433      0.665      -0.059       0.038\n",
      "x2_NE                                   -0.0038      0.011     -0.355      0.723      -0.025       0.017\n",
      "x2_NH                                   -0.0024      0.013     -0.179      0.858      -0.029       0.024\n",
      "x2_NJ                                    0.0021      0.008      0.272      0.786      -0.013       0.017\n",
      "x2_NM                                   -0.0493      0.025     -1.975      0.048      -0.098      -0.000\n",
      "x2_NV                                   -0.0095      0.009     -1.022      0.307      -0.028       0.009\n",
      "x2_NY                                   -0.0037      0.007     -0.511      0.610      -0.018       0.011\n",
      "x2_OH                                    0.0007      0.007      0.098      0.922      -0.014       0.015\n",
      "x2_OK                                   -0.0003      0.009     -0.028      0.978      -0.019       0.018\n",
      "x2_ON                                   -0.0343      0.017     -1.978      0.048      -0.068      -0.000\n",
      "x2_OR                                    0.0002      0.009      0.023      0.982      -0.018       0.019\n",
      "x2_PA                                    0.0009      0.008      0.118      0.906      -0.014       0.016\n",
      "x2_PR                                    0.0032      0.016      0.195      0.846      -0.029       0.035\n",
      "x2_QC                                   -0.0057      0.027     -0.215      0.830      -0.058       0.047\n",
      "x2_RI                                    0.0127      0.012      1.052      0.293      -0.011       0.036\n",
      "x2_SC                                   -0.0203      0.011     -1.919      0.055      -0.041       0.000\n",
      "x2_SD                                    0.0180      0.012      1.445      0.148      -0.006       0.042\n",
      "x2_TN                                   -0.0017      0.008     -0.207      0.836      -0.018       0.015\n",
      "x2_TX                                   -0.0048      0.007     -0.661      0.508      -0.019       0.009\n",
      "x2_UNKOWN                                0.0041      0.012      0.345      0.730      -0.019       0.027\n",
      "x2_UT                                   -0.0223      0.009     -2.465      0.014      -0.040      -0.005\n",
      "x2_VA                                    0.0008      0.008      0.100      0.920      -0.014       0.016\n",
      "x2_VT                                    0.0306      0.071      0.432      0.666      -0.108       0.170\n",
      "x2_WA                                    0.0050      0.008      0.599      0.549      -0.011       0.021\n",
      "x2_WI                                   -0.0138      0.008     -1.685      0.092      -0.030       0.002\n",
      "x2_WV                                   -0.0119      0.016     -0.766      0.444      -0.042       0.019\n",
      "x2_WY                                   -0.0257      0.028     -0.921      0.357      -0.080       0.029\n",
      "==============================================================================\n",
      "Omnibus:                     2482.064   Durbin-Watson:                   1.698\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12928.163\n",
      "Skew:                           0.618   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.126   Cond. No.                     2.94e+07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.94e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "y = data[['FEMALE_PCT']]\n",
    "X = data[data.columns.difference(['FEMALE_PCT'])]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "## creating function to get model statistics\n",
    "#def get_stats():\n",
    "    #results = sm.OLS(y, X).fit()\n",
    "    #print(results.summary())\n",
    "#get_stats()\n",
    "\n",
    "est = sm.OLS(y, X)\n",
    "est = est.fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS, Ridge, Lasso, and Elastic Net Regression\n",
    "from: https://urldefense.com/v3/__https://towardsdatascience.com/a-practical-suggestion-in-linear-regression-cb639fd5ccdb__;!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_YY6LnweQ$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes above can easily run into an overfitting problem. Overfitting means your model performs much better in the training data comparing to that in the testing data.\n",
    "\n",
    "The reason that drives to the overfitting problem is usually the high complexity of the model. In the code above, pooling all the features in X to the linear regression model will make it hard to make predictions on the future coming data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data.columns.difference(['FEMALE_PCT'])]\n",
    "y = data[['FEMALE_PCT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_fit = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that R2 is not always the square of anything, so it can have a negative value without violating any rules of math. R2 is negative only when the chosen model does not follow the trend of the data, so fits worse than a horizontal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross validation score: 0.6963844776595737\n",
      "score without cv: 0.720487512572366\n",
      "r2 score: 0.7216545631884552\n",
      "score: 0.7216545631884552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "regressor_scores = cross_val_score(model_fit, X_train, y_train, cv = 5)\n",
    "print(\"mean cross validation score: {}\".format(np.mean(regressor_scores)))\n",
    "print(\"score without cv: {}\".format(model_fit.score(X_train, y_train)))\n",
    "\n",
    "# on the test or hold-out set\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2 score: ' + str(r2_score(y_test, model_fit.predict(X_test))))\n",
    "print('score: ' + str(model_fit.score(X_test, y_test)))\n",
    "\n",
    "y_pred = model_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the mean absolute error which can be interpreted as the average distance from our predictions and the actual values.\n",
    "\n",
    "For other evaluation metrics, refer to: https://urldefense.com/v3/__https://scikit-learn.org/stable/modules/model_evaluation.html__;!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_YvLNtW9U$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04383517288837195"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004973039097337323"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7216545631884552"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7217034284043118"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, the complexity of a linear model can be reduced by two ways, feature engineering, and regularization.\n",
    "\n",
    "Feature engineering means you manually select a subset of the features from your raw table of X, however, this procedure also requires the preknowledge of the dataset that can guide the feature filtering.\n",
    "\n",
    "Regularization reduces the complexity of a linear model. Ridge regression, LASSO regression, as well as Elastic Net are three implementations for the purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression\n",
    "Ridge adds an ‘l2 norm’ penalty term to the original loss function of the linear regression, which tends to shrink the coefficients of all the variables to a certain level (based on the strength of regularization). The code is as below.\n",
    "\n",
    "\"my_alpha\" is the mentioned strength. The higher my_alpha is, the stronger the regularization is and the lower variance the model has."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is run in another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Train a model with default alpha = 0.1\n",
    "ridge = Ridge(alpha = 0.1).fit(X_train, y_train)\n",
    "\n",
    "# Find optimal alpha with grid serach\n",
    "alpha = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_grid = dict(alpha=alpha)\n",
    "grid = GridSearchCV(estimator=ridge, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 100\n",
    "ridge = Ridge(alpha = alpha)\n",
    "ridge_fit = ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "regressor_scores = cross_val_score(ridge_fit, X_train, y_train, cv = 5)\n",
    "print(\"mean cross validation score: {}\".format(np.mean(regressor_scores)))\n",
    "print(\"score without cv: {}\".format(ridge_fit.score(X_train, y_train)))\n",
    "\n",
    "# on the test or hold-out set\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2 score: ' + str(r2_score(y_test, ridge_fit.predict(X_test))))\n",
    "print('score: ' + str(ridge_fit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = ridge_fit.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO regression\n",
    "The idea of LASSO regression is similar to that of Ridge regression, but replace the ‘l2 norm’ by ‘l1 norm’ in the penalty function.\n",
    "\n",
    "This difference between LASSO and Ridge can result in that LASSO can shrink the coefficients to 0, while Ridge cannot. That’s why people also say LASSO has the ability to do the feature selection. The code is as below.\n",
    "\n",
    "If my_alpha is large enough, it will shrink all the coefficients to zero, which results in the most biased linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is run in another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Train a model with default alpha = 0.1\n",
    "lasso = Lasso(alpha = 0.1).fit(X_train, y_train)\n",
    "\n",
    "# Find optimal alpha with grid serach\n",
    "alpha = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_grid = dict(alpha=alpha)\n",
    "grid = GridSearchCV(estimator=lasso, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "lasso = Lasso(alpha = alpha)\n",
    "lasso_fit = ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "regressor_scores = cross_val_score(lasso_fit, X_train, y_train, cv = 5)\n",
    "print(\"mean cross validation score: {}\".format(np.mean(regressor_scores)))\n",
    "print(\"score without cv: {}\".format(lasso_fit.score(X_train, y_train)))\n",
    "\n",
    "# on the test or hold-out set\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2 score: ' + str(r2_score(y_test, lasso_fit.predict(X_test))))\n",
    "print('score: ' + str(lasso_fit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso_fit.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net\n",
    "Elastic Net is created to mix both LASSO and Ridge, in which the penalty term is a combination of l1 and l2 norm regularization terms. It induced one more parameter l1_ratio to assign two different weights to l1 and l2 norm which sum up to 1. The code is as below.\n",
    "\n",
    "In real practice, the best l1_ratio is always tuned via cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is run in another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net Regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Train model with default alpha=1 and l1_ratio=0.5\n",
    "elastic_net = ElasticNet(alpha=1, l1_ratio=0.5).fit(X_train, y_train)\n",
    "\n",
    "# find optimal alpha with grid search\n",
    "alpha = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "l1_ratio = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "param_grid = dict(alpha=alpha, l1_ratio=l1_ratio)\n",
    "grid = GridSearchCV(estimator=elastic_net, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "l1ratio = 0.5\n",
    "my_model = ElasticNet(alpha = alpha, l1_ratio = l1ratio)\n",
    "elastic_fit = my_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "regressor_scores = cross_val_score(elastic_fit, X_train, y_train, cv = 5)\n",
    "print(\"mean cross validation score: {}\".format(np.mean(regressor_scores)))\n",
    "print(\"score without cv: {}\".format(elastic_fit.score(X_train, y_train)))\n",
    "\n",
    "# on the test or hold-out set\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2 score: ' + str(r2_score(y_test, elastic_fit.predict(X_test))))\n",
    "print('score: ' + str(elastic_fit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = elastic_fit.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression\n",
    "from: https://urldefense.com/v3/__https://towardsdatascience.com/https-medium-com-lorrli-classification-and-regression-analysis-with-decision-trees-c43cdbc58054__;!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_YY3wcSIE$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is run in another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "# Train model with default\n",
    "decisiontree = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "\n",
    "# find optimal alpha with grid search\n",
    "\n",
    "criterion = ['mse', 'friedman_mse', 'mae']\n",
    "splitter = ['best', 'random']\n",
    "max_depth = [1,2,3,None]\n",
    "min_samples_split = [1,2,3,None]\n",
    "\n",
    "param_grid = dict(criterion=criterion, \n",
    "                  splitter=splitter,\n",
    "                  max_depth=max_depth,\n",
    "                  min_samples_split = min_samples_split\n",
    "                 )\n",
    "\n",
    "grid = GridSearchCV(estimator=decisiontree, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = 'mse'\n",
    "splitter = 'random'\n",
    "max_depth = 5\n",
    "min_samples_split = 3\n",
    "\n",
    "decisiontree = DecisionTreeRegressor(criterion = criterion, splitter = splitter, \n",
    "                                     max_depth = max_depth, min_samples_split = min_samples_split)\n",
    "decisiontree_fit = decisiontree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "regressor_scores = cross_val_score(decisiontree_fit, X_train, y_train, cv = 5)\n",
    "print(\"mean cross validation score: {}\".format(np.mean(regressor_scores)))\n",
    "print(\"score without cv: {}\".format(decisiontree_fit.score(X_train, y_train)))\n",
    "\n",
    "# on the test or hold-out set\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2 score: ' + str(r2_score(y_test, decisiontree_fit.predict(X_test))))\n",
    "print('score: ' + str(decisiontree_fit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decisiontree_fit.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "https://urldefense.com/v3/__https://scikit-learn.org/stable/modules/classes.html*module-sklearn.ensemble__;Iw!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_YCAvmouc$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree Regression\n",
    "from: https://urldefense.com/v3/__https://towardsdatascience.com/machine-learning-part-18-boosting-algorithms-gradient-boosting-in-python-ef5ae6965be4__;!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_YtJFz9iY$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is run in another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Train model with default parameter\n",
    "gradient = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "\n",
    "# find optimal alpha with grid search\n",
    "\n",
    "learning_rate = [0.01, 0.1, 1, 10, 100]\n",
    "max_depth = [1,2,3,4,5,None]\n",
    "min_samples_split = [1,2,3,None]\n",
    "\n",
    "param_grid = dict(learning_rate=learning_rate, \n",
    "                  max_depth=max_depth,\n",
    "                  min_samples_split = min_samples_split\n",
    "                 )\n",
    "\n",
    "grid = GridSearchCV(estimator=gradient, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =\n",
    "n_estimator =\n",
    "max_depth = \n",
    "min_samples_split = \n",
    "\n",
    "gradient = GradientBoostingRegressor(learning_rate = , n_estimator = , max_depth = , min_samples_split =)\n",
    "gradient_fit = gradient.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_regressor.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Regressor\n",
    "https://urldefense.com/v3/__https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html*sklearn.ensemble.AdaBoostRegressor__;Iw!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_YYpPzKXw$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is run in another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "adaboost = AdaBoostRegressor(random_state=42, n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "n_estimators = [25, 50, 100, 150]\n",
    "learning_rate = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "loss = ['linear', 'square', 'exponential']\n",
    "\n",
    "param_grid = dict(n_estimators = n_estimators, \n",
    "                  learning_rate = learning_rate, \n",
    "                  loss = loss)\n",
    "\n",
    "grid = GridSearchCV(estimator=adaboost, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ada Boost Regression\n",
    "n_estimators = 150\n",
    "learning_rate = 4.0\n",
    "loss = 'exponential'\n",
    "\n",
    "adaboost = AdaBoostRegressor(n_estimators = n_estimators, learning_rate = learning_rate, loss = loss)\n",
    "adaboost_fit = adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "regressor_scores = cross_val_score(adaboost_fit, X_train, y_train, cv = 5)\n",
    "print(\"mean cross validation score: {}\".format(np.mean(regressor_scores)))\n",
    "print(\"score without cv: {}\".format(adaboost_fit.score(X_train, y_train)))\n",
    "\n",
    "# on the test or hold-out set\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2 score: ' + str(r2_score(y_test, adaboost_fit.predict(X_test))))\n",
    "print('score: ' + str(adaboost_fit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = adaboost_fit.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Regressor\n",
    "https://urldefense.com/v3/__https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html*sklearn.ensemble.BaggingRegressor__;Iw!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_YbjO8bgc$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 280 candidates, totalling 1400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1400 out of 1400 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.713326143166313\n",
      "Best Params:  {'bootstrap': False, 'max_features': 100, 'max_samples': 10000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "bagging = BaggingRegressor(random_state=42, n_estimators=100).fit(X_train, y_train.values.ravel())\n",
    "\n",
    "max_samples = [1,2,3,4,5,10,50,100,500,1000,10000,50000,100000,None]\n",
    "max_features = [1,2,3,4,5,10,50,100,500,None]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = dict(max_samples = max_samples, \n",
    "                  max_features = max_features, \n",
    "                  bootstrap = bootstrap)\n",
    "\n",
    "grid = GridSearchCV(estimator=bagging, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train.values.ravel())\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross validation score: 0.6473651969539882\n",
      "score without cv: 0.9767796976168865\n",
      "r2 score: 0.7129373485836231\n",
      "score: 0.7129373485836231\n"
     ]
    }
   ],
   "source": [
    "# Bagging Regression\n",
    "bagging = BaggingRegressor(bootstrap = False, \n",
    "                           max_features = 100, \n",
    "                           max_samples = 10000 \n",
    "                           )\n",
    "bagging_fit = bagging.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "regressor_scores = cross_val_score(bagging_fit, X_train, y_train, cv = 10)\n",
    "print(\"mean cross validation score: {}\".format(np.mean(regressor_scores)))\n",
    "print(\"score without cv: {}\".format(bagging_fit.score(X_train, y_train.values.ravel())))\n",
    "\n",
    "# on the test or hold-out set\n",
    "print('r2 score: ' + str(r2_score(y_test, bagging_fit.predict(X_test))))\n",
    "print('score: ' + str(bagging_fit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04751944825043042"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = bagging_fit.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005183964386193745"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees Regressor\n",
    "https://urldefense.com/v3/__https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html*sklearn.ensemble.ExtraTreesRegressor__;Iw!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_YwQp2WiA$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-ff3f55146b62>:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  extratrees = ExtraTreesRegressor(random_state=42, n_estimators=100).fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 15.8min finished\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7386497894945516\n",
      "Best Params:  {'bootstrap': True, 'max_depth': None, 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "extratrees = ExtraTreesRegressor(random_state=42, n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "max_depth = [1,2,3,None]\n",
    "min_samples_split = [1,2,3]\n",
    "min_samples_leaf = [1,2,3]\n",
    "max_leaf_nodes = [1,2,3,None]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = dict( \n",
    "                  max_depth = max_depth, \n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf,\n",
    "                  max_leaf_nodes = max_leaf_nodes,\n",
    "                  bootstrap = bootstrap\n",
    "                 )\n",
    "\n",
    "grid = GridSearchCV(estimator=extratrees, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-0183e0199e11>:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  extratrees_fit = extratrees.fit(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "# Extratrees Regression\n",
    "extratrees = ExtraTreesRegressor(max_depth = None,\n",
    "                                 min_samples_split = 2,\n",
    "                                 min_samples_leaf = 2,\n",
    "                                 max_leaf_nodes = None,\n",
    "                                 bootstrap = True)\n",
    "extratrees_fit = extratrees.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross validation score: 0.7383701185052101\n",
      "score without cv: 0.9328277127149665\n",
      "r2 score: 0.7620150089411097\n",
      "score: 0.7620150089411097\n"
     ]
    }
   ],
   "source": [
    "regressor_scores = cross_val_score(extratrees_fit, X_train, y_train, cv = 5)\n",
    "print(\"mean cross validation score: {}\".format(np.mean(regressor_scores)))\n",
    "print(\"score without cv: {}\".format(extratrees_fit.score(X_train, y_train)))\n",
    "\n",
    "# on the test or hold-out set\n",
    "print('r2 score: ' + str(r2_score(y_test, extratrees_fit.predict(X_test))))\n",
    "print('score: ' + str(extratrees_fit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = extratrees_fit.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004251942042493894"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "https://urldefense.com/v3/__https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html*sklearn.ensemble.RandomForestRegressor__;Iw!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_YST_WGu4$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:  7.3min finished\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7399377947551506\n",
      "Best Params:  {'bootstrap': True, 'max_depth': None, 'max_leaf_nodes': None, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "randomforestregression = RandomForestRegressor(random_state=42, n_estimators=100).fit(X_train, y_train.values.ravel())\n",
    "\n",
    "max_depth = [1,2,3,None]\n",
    "min_samples_split = [1,2,3,None]\n",
    "max_leaf_nodes = [1,2,3,None]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = dict(\n",
    "                  max_depth = max_depth, \n",
    "                  min_samples_split = min_samples_split,\n",
    "                  max_leaf_nodes = max_leaf_nodes,\n",
    "                  bootstrap = bootstrap\n",
    "                 )\n",
    "\n",
    "grid = GridSearchCV(estimator=extratrees, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-a4defdf1d79a>:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomforestregression_fit = randomforestregression.fit(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regression\n",
    "bootstrap = True\n",
    "max_depth = None \n",
    "max_leaf_nodes = None \n",
    "min_samples_split = 3\n",
    "\n",
    "randomforestregression = RandomForestRegressor(\n",
    "                                               max_depth = max_depth, \n",
    "                                               min_samples_split = min_samples_split,\n",
    "                                               max_leaf_nodes = max_leaf_nodes,\n",
    "                                               bootstrap = bootstrap)\n",
    "randomforestregression_fit = randomforestregression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross validation score: 0.73956314348425\n",
      "score without cv: 0.9610750179433731\n",
      "r2 score: 0.7591460602318454\n",
      "score: 0.7591460602318454\n"
     ]
    }
   ],
   "source": [
    "regressor_scores = cross_val_score(randomforestregression_fit, X_train, y_train, cv = 5)\n",
    "print(\"mean cross validation score: {}\".format(np.mean(regressor_scores)))\n",
    "print(\"score without cv: {}\".format(randomforestregression_fit.score(X_train, y_train)))\n",
    "\n",
    "# on the test or hold-out set\n",
    "print('r2 score: ' + str(r2_score(y_test, randomforestregression_fit.predict(X_test))))\n",
    "print('score: ' + str(randomforestregression_fit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0382622963601754"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = randomforestregression_fit.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004303199912078034"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Regressor\n",
    "https://urldefense.com/v3/__https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html*sklearn.ensemble.StackingRegressor__;Iw!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_Ys7B4UiA$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  3.0min finished\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.632248605596203\n",
      "Best Params:  {'cv': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "estimators = [\n",
    "('lr', RidgeCV()),\n",
    "('svr', LinearSVR(random_state=42))]\n",
    "stacking = StackingRegressor(estimators=estimators,\n",
    "                             final_estimator=RandomForestRegressor(n_estimators=10,random_state=42)).fit(X_train, y_train)\n",
    "\n",
    "cv = [3,10,None]\n",
    "param_grid = dict(cv = cv)\n",
    "grid = GridSearchCV(estimator=stacking, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Stacking Regressor\n",
    "stacking = StackingRegressor(estimators = estimators, cv = None)\n",
    "stacking_fit = stacking.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross validation score: 0.5116255768443104\n",
      "score without cv: 0.6430900504964924\n",
      "r2 score: 0.6481826707406801\n",
      "score: 0.6481826707406801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SXJ8JOZ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "regressor_scores = cross_val_score(stacking_fit, X_train, y_train, cv = 5)\n",
    "print(\"mean cross validation score: {}\".format(np.mean(regressor_scores)))\n",
    "print(\"score without cv: {}\".format(stacking_fit.score(X_train, y_train)))\n",
    "\n",
    "# on the test or hold-out set\n",
    "print('r2 score: ' + str(r2_score(y_test, stacking_fit.predict(X_test))))\n",
    "print('score: ' + str(stacking_fit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05814980013378513"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stacking_fit.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006285719477096987"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hist Gradient Boosting Regressor\n",
    "https://urldefense.com/v3/__https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html*sklearn.ensemble.HistGradientBoostingRegressor__;Iw!!M-nmYVHPHQ!dcUnTVPG-I84aYa1Ers62bQZloP5GIGWh5mFqAuRlVpb-JbfJkxsO0v1rY_YfCgNqpk$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is run in another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "histgradient = HistGradientBoostingRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ['least_squares', 'least_absolute_deviation']\n",
    "learning_rate = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "max_iter = [50,100,150,200,250]\n",
    "max_leaf_nodes = [1,2,3,4,5,None]\n",
    "max_depth = [1,2,3,4,5,None]\n",
    "l2_regularization = [0,1,2,3,4,5]\n",
    "\n",
    "param_grid = dict(loss = loss,\n",
    "                  learning_rate = learning_rate,\n",
    "                  max_iter = max_iter,\n",
    "                  max_leaf_nodes = max_leaf_nodes,\n",
    "                  max_depth = max_depth,\n",
    "                  l2_regularization = l2_regularization\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=histgradient, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train, y_train)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hist Gradient Boosting Regressor\n",
    "histgradient = HistGradientBoostingRegressor(l2_regularization= 5, \n",
    "                                             learning_rate= 0.1, \n",
    "                                             loss= 'least_squares', \n",
    "                                             max_depth= None, \n",
    "                                             max_iter= 250, \n",
    "                                             max_leaf_nodes= None)\n",
    "histgradient_fit = histgradient.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regressor_scores = cross_val_score(histgradient_fit, X_train, y_train, cv = 5)\n",
    "print(\"mean cross validation score: {}\".format(np.mean(regressor_scores)))\n",
    "print(\"score without cv: {}\".format(histgradient_fit.score(X_train, y_train)))\n",
    "\n",
    "# on the test or hold-out set\n",
    "print('r2 score: ' + str(r2_score(y_test, histgradient_fit.predict(X_test))))\n",
    "print('score: ' + str(histgradient_fit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = histgradient_fit.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
